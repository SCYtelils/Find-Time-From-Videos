{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d74f247",
   "metadata": {},
   "source": [
    "### 预测代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd88e1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Administrator/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 97.8M/97.8M [00:06<00:00, 15.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back to the Future 10.03 p.m.png 10 4\n",
      "Barton Fink 7.59 a.m.png 7 59\n",
      "Basic 2.55 a.m. 1.png 2 55\n",
      "Batman 3.12 a.m.png 3 12\n",
      "Beauty and the Beast 7.00 p.m.png 6 59\n",
      "Beetlejuice 6.00 p.m.png 6 1\n",
      "Before the Devil Knows You're Dead 9.12 a.m.png 9 11\n",
      "Being There 6.49 p.m.png 6 49\n",
      "Big Daddy 10.41 a.m.png 10 40\n",
      "Big Fish 12.03 p.m.png 0 4\n",
      "Black Narcissus 5.58 a.m.png 5 57\n",
      "Black Narcissus 6.01 p.m.png 6 0\n",
      "Blackboard Jungle 3.25 p.m.png 3 25\n",
      "Brewster's Millions 11.57 p.m.png 11 56\n",
      "Buffalo '66 11.08 p.m.png 11 7\n",
      "Bullitt 6.51 p.m.png 6 52\n",
      "Burn After Reading 4.53 p.m.png 4 53\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import einops\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from natsort import natsorted\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import DataLoader\n",
    "from data import *\n",
    "from utils import warp, update_train_log, write_train_log, update_eval_log, write_eval_log, print_eval_log\n",
    "\n",
    "def main(args):\n",
    "  verbose = args.verbose\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "  # DATASET\n",
    "  images = [x for x in natsorted(os.listdir(args.dir)) if ('.jpg' in x) or ('.png' in x)]\n",
    "\n",
    "  # MODEL\n",
    "  model_stn = models.resnet50(pretrained=True)\n",
    "  model_stn.fc = nn.Linear(2048, 8)\n",
    "  model = models.resnet50(pretrained=True)\n",
    "  model.fc = nn.Linear(2048, 720)\n",
    "  resume_path = '../models/{}.pth'.format(args.verbose)\n",
    "  stn_resume_path = '../models/{}_st.pth'.format(args.verbose)\n",
    "  model.load_state_dict(torch.load(resume_path))\n",
    "  model_stn.load_state_dict(torch.load(stn_resume_path))\n",
    "  model_stn.to(device)\n",
    "  model.to(device)\n",
    "\n",
    "  for img_name in images:\n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      model_stn.eval()\n",
    "\n",
    "      #MODEL\n",
    "      img = cv2.imread(os.path.join(args.dir, img_name))\n",
    "      img = cv2.resize(img, (224, 224))/255.\n",
    "      img = einops.rearrange(img, 'h w c -> c h w')\n",
    "      img = torch.Tensor(img)\n",
    "      img = img.float().to(device)\n",
    "      img = torch.unsqueeze(img, 0)\n",
    "\n",
    "      pred_st = model_stn(img)\n",
    "      pred_st = torch.cat([pred_st,torch.ones(1,1).to(device)], 1)\n",
    "      Minv_pred = torch.reshape(pred_st, (-1, 3, 3))\n",
    "      img_ = warp(img, Minv_pred)\n",
    "      pred = model(img_)\n",
    "\n",
    "      #top 3 predictions\n",
    "      max_pred = torch.argsort(pred, dim=1, descending=True)\n",
    "      max_pred = max_pred[0,:3]\n",
    "      max_h = max_pred[0] // 60\n",
    "      max_m = max_pred[0] % 60\n",
    "\n",
    "      print(img_name, max_h.cpu().numpy(), max_m.cpu().numpy())\n",
    "      \n",
    "      #img = einops.rearrange(img[0], 'c h w -> h w c').cpu().numpy()[:,:,::-1] * 255 \n",
    "      #img_ = einops.rearrange(img_[0], 'c h w -> h w c').cpu().numpy()[:,:,::-1] * 255\n",
    "\n",
    "      #uncomment this to save image\n",
    "      #os.makedirs('../viz/{}/{}'.format(verbose,names[i]), exist_ok=True)\n",
    "      #if idx < 100:\n",
    "      #cv2.imwrite('../viz/{}/{}/{}_{}_{}.png'.format(verbose,names[i],idx, int(max_pred[0]), int(hr*60+mn)), img)\n",
    "      #cv2.imwrite('../viz/{}/{}/{}_w.png'.format(verbose,names[i],idx), img_)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--verbose', type=str, default='full+++')\n",
    "    parser.add_argument('--dir', type=str, default='../data/demo')\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e4119",
   "metadata": {},
   "source": [
    "### 评估代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cfaffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 93\u001b[0m\n\u001b[0;32m     90\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--verbose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull+++\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     92\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args(args\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m---> 93\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 56\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#MODEL\u001b[39;00m\n\u001b[0;32m     55\u001b[0m pred_st \u001b[38;5;241m=\u001b[39m model_stn(img)\n\u001b[1;32m---> 56\u001b[0m pred_st \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([pred_st,\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     57\u001b[0m Minv_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(pred_st, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m     58\u001b[0m img_ \u001b[38;5;241m=\u001b[39m warp(img, Minv_pred)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import einops\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import DataLoader\n",
    "from data import *\n",
    "from utils import warp, update_train_log, write_train_log, update_eval_log, write_eval_log, print_eval_log\n",
    "\n",
    "def main(args):\n",
    "  verbose = args.verbose\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "  # DATASET\n",
    "  coco_dataset = ClockEval('coco')\n",
    "  openimg_dataset = ClockEval('openimages')\n",
    "  movie_dataset = ClockEval('clockmovies')\n",
    "  coco_loader = DataLoader(coco_dataset, batch_size=1, shuffle=False)\n",
    "  openimg_loader = DataLoader(openimg_dataset, batch_size=1, shuffle=False)\n",
    "  movie_loader = DataLoader(movie_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "  # MODEL\n",
    "  model_stn = models.resnet50(pretrained=True)\n",
    "  model_stn.fc = nn.Linear(2048, 8)\n",
    "  model = models.resnet50(pretrained=True)\n",
    "  model.fc = nn.Linear(2048, 720)\n",
    "  resume_path = '../models/{}.pth'.format(args.verbose)\n",
    "  stn_resume_path = '../models/{}_st.pth'.format(args.verbose)\n",
    "  model.load_state_dict(torch.load(resume_path))\n",
    "  model_stn.load_state_dict(torch.load(stn_resume_path))\n",
    "  model_stn.to(device)\n",
    "  model.to(device)\n",
    "\n",
    "  names = ['COCO', 'OpenImages', 'ClockMovies']\n",
    "  for i, vloader in enumerate([coco_loader, openimg_loader]):\n",
    "    eval_log = {'top_1': [],'top_2': [],'top_3': [],'top_1_hr': [], 'top_1_min': [], 'iou50': []}\n",
    "    for idx, val_sample in enumerate(vloader):\n",
    "      with torch.no_grad():\n",
    "        model.eval()\n",
    "        model_stn.eval()\n",
    "        \n",
    "        img, hour, minute, iou50 = val_sample\n",
    "        img = img.float().to(device)\n",
    "        hr = hour.type(torch.long).to(device)\n",
    "        mn = minute.type(torch.long).to(device)\n",
    "\n",
    "        #MODEL\n",
    "        pred_st = model_stn(img)\n",
    "        pred_st = torch.cat([pred_st,torch.ones(1,1).to(device)], 1)\n",
    "        Minv_pred = torch.reshape(pred_st, (-1, 3, 3))\n",
    "        img_ = warp(img, Minv_pred)\n",
    "        pred = model(img_)\n",
    "\n",
    "\n",
    "        #top 3 predictions\n",
    "        max_pred = torch.argsort(pred, dim=1, descending=True)\n",
    "        max_pred = max_pred[0,:3]\n",
    "        max_h = max_pred[0] // 60\n",
    "        max_m = max_pred[0] % 60\n",
    "\n",
    "        minute_err = torch.sum(torch.abs(max_m - mn))\n",
    "        both_err = torch.abs(max_pred - (hr * 60 + mn))\n",
    "        top_1 = float(both_err[0] <= 1) + float(both_err[0] == 719)\n",
    "        top_2 = float(both_err[1] <= 1) + float(both_err[1] == 719)\n",
    "        top_3 = float(both_err[2] <= 1) + float(both_err[2] == 719)\n",
    "        top_1_hr = float(torch.sum(max_h == hr))\n",
    "        top_1_min = float(minute_err <= 1) + float(minute_err == 59)\n",
    "\n",
    "        update_eval_log(eval_log, top_1, top_2, top_3, top_1_hr, top_1_min, int(iou50))\n",
    "        img = einops.rearrange(img[0], 'c h w -> h w c').cpu().numpy()[:,:,::-1] * 255 \n",
    "        img_ = einops.rearrange(img_[0], 'c h w -> h w c').cpu().numpy()[:,:,::-1] * 255\n",
    "\n",
    "        #uncomment this to save image\n",
    "        #os.makedirs('../viz/{}/{}'.format(verbose,names[i]), exist_ok=True)\n",
    "        #if idx < 100:\n",
    "        #cv2.imwrite('../viz/{}/{}/{}_{}_{}.png'.format(verbose,names[i],idx, int(max_pred[0]), int(hr*60+mn)), img)\n",
    "        #cv2.imwrite('../viz/{}/{}/{}_w.png'.format(verbose,names[i],idx), img_)\n",
    "\n",
    "    print_eval_log(eval_log, i)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--verbose', type=str, default='full+++')\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9341ac",
   "metadata": {},
   "source": [
    "### train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305fc6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Batch 0/2500 - Loss: 53.9032, Hour Accuracy: 0.0938, Minute Accuracy: 0.0938\n",
      "Batch 10/2500 - Loss: 39.9347, Hour Accuracy: 0.1562, Minute Accuracy: 0.0312\n",
      "Batch 20/2500 - Loss: 26.2138, Hour Accuracy: 0.0312, Minute Accuracy: 0.0000\n",
      "Batch 30/2500 - Loss: 22.4486, Hour Accuracy: 0.2188, Minute Accuracy: 0.0625\n",
      "Batch 40/2500 - Loss: 21.5645, Hour Accuracy: 0.0625, Minute Accuracy: 0.0312\n",
      "Batch 50/2500 - Loss: 19.2791, Hour Accuracy: 0.1562, Minute Accuracy: 0.0938\n",
      "Batch 60/2500 - Loss: 16.4688, Hour Accuracy: 0.1875, Minute Accuracy: 0.0312\n",
      "Batch 70/2500 - Loss: 18.2203, Hour Accuracy: 0.1562, Minute Accuracy: 0.0938\n",
      "Batch 80/2500 - Loss: 16.9972, Hour Accuracy: 0.1875, Minute Accuracy: 0.0000\n",
      "Batch 90/2500 - Loss: 16.9511, Hour Accuracy: 0.1250, Minute Accuracy: 0.0000\n",
      "Batch 100/2500 - Loss: 14.4926, Hour Accuracy: 0.1562, Minute Accuracy: 0.0312\n",
      "Batch 110/2500 - Loss: 14.3264, Hour Accuracy: 0.1875, Minute Accuracy: 0.0938\n",
      "Batch 120/2500 - Loss: 15.4108, Hour Accuracy: 0.1875, Minute Accuracy: 0.0312\n",
      "Batch 130/2500 - Loss: 15.2768, Hour Accuracy: 0.0938, Minute Accuracy: 0.0625\n",
      "Batch 140/2500 - Loss: 14.8028, Hour Accuracy: 0.0938, Minute Accuracy: 0.0000\n",
      "Batch 150/2500 - Loss: 14.1565, Hour Accuracy: 0.0938, Minute Accuracy: 0.0938\n",
      "Batch 160/2500 - Loss: 14.2190, Hour Accuracy: 0.2188, Minute Accuracy: 0.0625\n",
      "Batch 170/2500 - Loss: 13.8804, Hour Accuracy: 0.2188, Minute Accuracy: 0.0312\n",
      "Batch 180/2500 - Loss: 12.8813, Hour Accuracy: 0.2500, Minute Accuracy: 0.1562\n",
      "Batch 190/2500 - Loss: 14.2030, Hour Accuracy: 0.2500, Minute Accuracy: 0.1250\n",
      "Batch 200/2500 - Loss: 14.7788, Hour Accuracy: 0.1250, Minute Accuracy: 0.0625\n",
      "Batch 210/2500 - Loss: 12.7089, Hour Accuracy: 0.1562, Minute Accuracy: 0.0312\n",
      "Batch 220/2500 - Loss: 13.3750, Hour Accuracy: 0.1562, Minute Accuracy: 0.0000\n",
      "Batch 230/2500 - Loss: 13.5087, Hour Accuracy: 0.0938, Minute Accuracy: 0.0000\n",
      "Batch 240/2500 - Loss: 13.4494, Hour Accuracy: 0.1562, Minute Accuracy: 0.0938\n",
      "Batch 250/2500 - Loss: 12.7280, Hour Accuracy: 0.1562, Minute Accuracy: 0.0312\n",
      "Batch 260/2500 - Loss: 13.7995, Hour Accuracy: 0.1875, Minute Accuracy: 0.0312\n",
      "Batch 270/2500 - Loss: 12.9207, Hour Accuracy: 0.1250, Minute Accuracy: 0.0312\n",
      "Batch 280/2500 - Loss: 12.5356, Hour Accuracy: 0.3125, Minute Accuracy: 0.0938\n",
      "Batch 290/2500 - Loss: 13.4427, Hour Accuracy: 0.2188, Minute Accuracy: 0.0312\n",
      "Batch 300/2500 - Loss: 13.1349, Hour Accuracy: 0.2188, Minute Accuracy: 0.0938\n",
      "Batch 310/2500 - Loss: 13.2934, Hour Accuracy: 0.2188, Minute Accuracy: 0.1250\n",
      "Batch 320/2500 - Loss: 13.0671, Hour Accuracy: 0.2812, Minute Accuracy: 0.0312\n",
      "Batch 330/2500 - Loss: 13.5660, Hour Accuracy: 0.2188, Minute Accuracy: 0.0312\n",
      "Batch 340/2500 - Loss: 12.4878, Hour Accuracy: 0.1875, Minute Accuracy: 0.0312\n",
      "Batch 350/2500 - Loss: 12.1399, Hour Accuracy: 0.1562, Minute Accuracy: 0.0312\n",
      "Batch 360/2500 - Loss: 12.4972, Hour Accuracy: 0.2500, Minute Accuracy: 0.1250\n",
      "Batch 370/2500 - Loss: 11.9838, Hour Accuracy: 0.2188, Minute Accuracy: 0.1250\n",
      "Batch 380/2500 - Loss: 12.1273, Hour Accuracy: 0.1562, Minute Accuracy: 0.0938\n",
      "Batch 390/2500 - Loss: 13.7076, Hour Accuracy: 0.2500, Minute Accuracy: 0.0938\n",
      "Batch 400/2500 - Loss: 12.5060, Hour Accuracy: 0.3438, Minute Accuracy: 0.0938\n",
      "Batch 410/2500 - Loss: 12.0739, Hour Accuracy: 0.1562, Minute Accuracy: 0.1875\n",
      "Batch 420/2500 - Loss: 11.6208, Hour Accuracy: 0.2500, Minute Accuracy: 0.0625\n",
      "Batch 430/2500 - Loss: 11.9017, Hour Accuracy: 0.1250, Minute Accuracy: 0.1250\n",
      "Batch 440/2500 - Loss: 11.4520, Hour Accuracy: 0.2812, Minute Accuracy: 0.1875\n",
      "Batch 450/2500 - Loss: 11.6936, Hour Accuracy: 0.1875, Minute Accuracy: 0.1562\n",
      "Batch 460/2500 - Loss: 14.1111, Hour Accuracy: 0.1562, Minute Accuracy: 0.0000\n",
      "Batch 470/2500 - Loss: 10.9096, Hour Accuracy: 0.1562, Minute Accuracy: 0.0625\n",
      "Batch 480/2500 - Loss: 11.6222, Hour Accuracy: 0.1875, Minute Accuracy: 0.0312\n",
      "Batch 490/2500 - Loss: 11.6133, Hour Accuracy: 0.1875, Minute Accuracy: 0.1250\n",
      "Batch 500/2500 - Loss: 12.7547, Hour Accuracy: 0.1875, Minute Accuracy: 0.0938\n",
      "Batch 510/2500 - Loss: 11.4080, Hour Accuracy: 0.1562, Minute Accuracy: 0.1250\n",
      "Batch 520/2500 - Loss: 11.3450, Hour Accuracy: 0.2812, Minute Accuracy: 0.0938\n",
      "Batch 530/2500 - Loss: 11.0194, Hour Accuracy: 0.2500, Minute Accuracy: 0.2188\n",
      "Batch 540/2500 - Loss: 10.5231, Hour Accuracy: 0.3438, Minute Accuracy: 0.0625\n",
      "Batch 550/2500 - Loss: 11.4529, Hour Accuracy: 0.1250, Minute Accuracy: 0.0938\n",
      "Batch 560/2500 - Loss: 11.0914, Hour Accuracy: 0.2812, Minute Accuracy: 0.1250\n",
      "Batch 570/2500 - Loss: 12.2969, Hour Accuracy: 0.1250, Minute Accuracy: 0.1250\n",
      "Batch 580/2500 - Loss: 12.0638, Hour Accuracy: 0.1875, Minute Accuracy: 0.2188\n",
      "Batch 590/2500 - Loss: 11.0247, Hour Accuracy: 0.3438, Minute Accuracy: 0.1562\n",
      "Batch 600/2500 - Loss: 13.0537, Hour Accuracy: 0.1562, Minute Accuracy: 0.1875\n",
      "Batch 610/2500 - Loss: 10.4660, Hour Accuracy: 0.3125, Minute Accuracy: 0.1250\n",
      "Batch 620/2500 - Loss: 11.7239, Hour Accuracy: 0.3438, Minute Accuracy: 0.1562\n",
      "Batch 630/2500 - Loss: 11.7796, Hour Accuracy: 0.1562, Minute Accuracy: 0.2500\n",
      "Batch 640/2500 - Loss: 10.4427, Hour Accuracy: 0.2188, Minute Accuracy: 0.1562\n",
      "Batch 650/2500 - Loss: 13.1986, Hour Accuracy: 0.4062, Minute Accuracy: 0.1250\n",
      "Batch 660/2500 - Loss: 10.1673, Hour Accuracy: 0.4062, Minute Accuracy: 0.1562\n",
      "Batch 670/2500 - Loss: 10.7346, Hour Accuracy: 0.2812, Minute Accuracy: 0.0938\n",
      "Batch 680/2500 - Loss: 11.1552, Hour Accuracy: 0.1250, Minute Accuracy: 0.1562\n",
      "Batch 690/2500 - Loss: 9.8109, Hour Accuracy: 0.3125, Minute Accuracy: 0.1875\n",
      "Batch 700/2500 - Loss: 11.2534, Hour Accuracy: 0.2188, Minute Accuracy: 0.1875\n",
      "Batch 710/2500 - Loss: 9.8740, Hour Accuracy: 0.4062, Minute Accuracy: 0.2500\n",
      "Batch 720/2500 - Loss: 10.6088, Hour Accuracy: 0.3438, Minute Accuracy: 0.2188\n",
      "Batch 730/2500 - Loss: 12.1647, Hour Accuracy: 0.0625, Minute Accuracy: 0.1875\n",
      "Batch 740/2500 - Loss: 11.1536, Hour Accuracy: 0.1875, Minute Accuracy: 0.1250\n",
      "Batch 750/2500 - Loss: 10.3302, Hour Accuracy: 0.2188, Minute Accuracy: 0.2812\n",
      "Batch 760/2500 - Loss: 11.2517, Hour Accuracy: 0.3438, Minute Accuracy: 0.2812\n",
      "Batch 770/2500 - Loss: 10.4595, Hour Accuracy: 0.2812, Minute Accuracy: 0.1875\n",
      "Batch 780/2500 - Loss: 11.6752, Hour Accuracy: 0.2812, Minute Accuracy: 0.1562\n",
      "Batch 790/2500 - Loss: 11.1794, Hour Accuracy: 0.2812, Minute Accuracy: 0.2500\n",
      "Batch 800/2500 - Loss: 9.4932, Hour Accuracy: 0.3125, Minute Accuracy: 0.2188\n",
      "Batch 810/2500 - Loss: 9.6293, Hour Accuracy: 0.4062, Minute Accuracy: 0.2188\n",
      "Batch 820/2500 - Loss: 10.0038, Hour Accuracy: 0.4375, Minute Accuracy: 0.1562\n",
      "Batch 830/2500 - Loss: 9.4963, Hour Accuracy: 0.2500, Minute Accuracy: 0.2812\n",
      "Batch 840/2500 - Loss: 10.8917, Hour Accuracy: 0.3438, Minute Accuracy: 0.1562\n",
      "Batch 850/2500 - Loss: 10.9842, Hour Accuracy: 0.1562, Minute Accuracy: 0.1875\n",
      "Batch 860/2500 - Loss: 10.6380, Hour Accuracy: 0.2812, Minute Accuracy: 0.1250\n",
      "Batch 870/2500 - Loss: 10.3130, Hour Accuracy: 0.4688, Minute Accuracy: 0.3125\n",
      "Batch 880/2500 - Loss: 10.3536, Hour Accuracy: 0.4688, Minute Accuracy: 0.3125\n",
      "Batch 890/2500 - Loss: 9.6378, Hour Accuracy: 0.3438, Minute Accuracy: 0.0938\n",
      "Batch 900/2500 - Loss: 10.5237, Hour Accuracy: 0.2812, Minute Accuracy: 0.0625\n",
      "Batch 910/2500 - Loss: 10.0775, Hour Accuracy: 0.3750, Minute Accuracy: 0.2188\n",
      "Batch 920/2500 - Loss: 10.0811, Hour Accuracy: 0.2812, Minute Accuracy: 0.1875\n",
      "Batch 930/2500 - Loss: 9.7159, Hour Accuracy: 0.3125, Minute Accuracy: 0.1562\n",
      "Batch 940/2500 - Loss: 8.6753, Hour Accuracy: 0.3438, Minute Accuracy: 0.3125\n",
      "Batch 950/2500 - Loss: 9.1451, Hour Accuracy: 0.3438, Minute Accuracy: 0.1562\n",
      "Batch 960/2500 - Loss: 9.5396, Hour Accuracy: 0.3125, Minute Accuracy: 0.2812\n",
      "Batch 970/2500 - Loss: 9.8743, Hour Accuracy: 0.2812, Minute Accuracy: 0.1875\n",
      "Batch 980/2500 - Loss: 9.6151, Hour Accuracy: 0.4375, Minute Accuracy: 0.2500\n",
      "Batch 990/2500 - Loss: 10.4616, Hour Accuracy: 0.4688, Minute Accuracy: 0.2500\n",
      "Batch 1000/2500 - Loss: 8.7851, Hour Accuracy: 0.3750, Minute Accuracy: 0.1562\n",
      "Batch 1010/2500 - Loss: 9.2940, Hour Accuracy: 0.5312, Minute Accuracy: 0.3125\n",
      "Batch 1020/2500 - Loss: 8.6436, Hour Accuracy: 0.5625, Minute Accuracy: 0.3125\n",
      "Batch 1030/2500 - Loss: 9.0243, Hour Accuracy: 0.3125, Minute Accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1040/2500 - Loss: 8.4865, Hour Accuracy: 0.3438, Minute Accuracy: 0.1875\n",
      "Batch 1050/2500 - Loss: 9.8708, Hour Accuracy: 0.4375, Minute Accuracy: 0.1562\n",
      "Batch 1060/2500 - Loss: 8.7159, Hour Accuracy: 0.4062, Minute Accuracy: 0.2812\n",
      "Batch 1070/2500 - Loss: 8.8095, Hour Accuracy: 0.5312, Minute Accuracy: 0.1875\n",
      "Batch 1080/2500 - Loss: 10.2803, Hour Accuracy: 0.3750, Minute Accuracy: 0.2812\n",
      "Batch 1090/2500 - Loss: 9.4814, Hour Accuracy: 0.4062, Minute Accuracy: 0.1875\n",
      "Batch 1100/2500 - Loss: 8.3335, Hour Accuracy: 0.5312, Minute Accuracy: 0.2500\n",
      "Batch 1110/2500 - Loss: 9.8326, Hour Accuracy: 0.5938, Minute Accuracy: 0.2188\n",
      "Batch 1120/2500 - Loss: 8.8084, Hour Accuracy: 0.5312, Minute Accuracy: 0.1875\n",
      "Batch 1130/2500 - Loss: 8.2571, Hour Accuracy: 0.4062, Minute Accuracy: 0.3438\n",
      "Batch 1140/2500 - Loss: 8.7180, Hour Accuracy: 0.4375, Minute Accuracy: 0.2812\n",
      "Batch 1150/2500 - Loss: 8.9013, Hour Accuracy: 0.3750, Minute Accuracy: 0.3125\n",
      "Batch 1160/2500 - Loss: 8.5571, Hour Accuracy: 0.3750, Minute Accuracy: 0.2188\n",
      "Batch 1170/2500 - Loss: 8.6462, Hour Accuracy: 0.5625, Minute Accuracy: 0.4688\n",
      "Batch 1180/2500 - Loss: 8.4133, Hour Accuracy: 0.5000, Minute Accuracy: 0.3438\n",
      "Batch 1190/2500 - Loss: 10.0714, Hour Accuracy: 0.2812, Minute Accuracy: 0.3125\n",
      "Batch 1200/2500 - Loss: 9.4595, Hour Accuracy: 0.5625, Minute Accuracy: 0.3750\n",
      "Batch 1210/2500 - Loss: 8.8194, Hour Accuracy: 0.4375, Minute Accuracy: 0.1250\n",
      "Batch 1220/2500 - Loss: 8.0868, Hour Accuracy: 0.5312, Minute Accuracy: 0.2812\n",
      "Batch 1230/2500 - Loss: 8.2304, Hour Accuracy: 0.5625, Minute Accuracy: 0.4062\n",
      "Batch 1240/2500 - Loss: 9.8446, Hour Accuracy: 0.4062, Minute Accuracy: 0.3125\n",
      "Batch 1250/2500 - Loss: 9.3917, Hour Accuracy: 0.3750, Minute Accuracy: 0.2812\n",
      "Batch 1260/2500 - Loss: 9.4108, Hour Accuracy: 0.3125, Minute Accuracy: 0.1875\n",
      "Batch 1270/2500 - Loss: 8.1757, Hour Accuracy: 0.4375, Minute Accuracy: 0.2188\n",
      "Batch 1280/2500 - Loss: 7.7865, Hour Accuracy: 0.5625, Minute Accuracy: 0.4062\n",
      "Batch 1290/2500 - Loss: 9.3104, Hour Accuracy: 0.4375, Minute Accuracy: 0.1875\n",
      "Batch 1300/2500 - Loss: 8.0685, Hour Accuracy: 0.4688, Minute Accuracy: 0.3438\n",
      "Batch 1310/2500 - Loss: 8.1478, Hour Accuracy: 0.4062, Minute Accuracy: 0.1562\n",
      "Batch 1320/2500 - Loss: 8.0768, Hour Accuracy: 0.5000, Minute Accuracy: 0.4062\n",
      "Batch 1330/2500 - Loss: 8.3362, Hour Accuracy: 0.5312, Minute Accuracy: 0.2812\n",
      "Batch 1340/2500 - Loss: 8.9103, Hour Accuracy: 0.3438, Minute Accuracy: 0.2500\n",
      "Batch 1350/2500 - Loss: 8.1675, Hour Accuracy: 0.4688, Minute Accuracy: 0.4062\n",
      "Batch 1360/2500 - Loss: 8.2912, Hour Accuracy: 0.4688, Minute Accuracy: 0.2188\n",
      "Batch 1370/2500 - Loss: 7.6182, Hour Accuracy: 0.5000, Minute Accuracy: 0.3125\n",
      "Batch 1380/2500 - Loss: 9.1403, Hour Accuracy: 0.4688, Minute Accuracy: 0.2500\n",
      "Batch 1390/2500 - Loss: 9.6080, Hour Accuracy: 0.3438, Minute Accuracy: 0.2188\n",
      "Batch 1400/2500 - Loss: 8.3408, Hour Accuracy: 0.5625, Minute Accuracy: 0.2812\n",
      "Batch 1410/2500 - Loss: 7.5393, Hour Accuracy: 0.5938, Minute Accuracy: 0.4062\n",
      "Batch 1420/2500 - Loss: 8.9945, Hour Accuracy: 0.4062, Minute Accuracy: 0.3750\n",
      "Batch 1430/2500 - Loss: 8.6725, Hour Accuracy: 0.6250, Minute Accuracy: 0.2812\n",
      "Batch 1440/2500 - Loss: 8.0236, Hour Accuracy: 0.4688, Minute Accuracy: 0.3438\n",
      "Batch 1450/2500 - Loss: 8.5157, Hour Accuracy: 0.5625, Minute Accuracy: 0.1562\n",
      "Batch 1460/2500 - Loss: 7.6503, Hour Accuracy: 0.4375, Minute Accuracy: 0.1875\n",
      "Batch 1470/2500 - Loss: 6.3883, Hour Accuracy: 0.6250, Minute Accuracy: 0.5625\n",
      "Batch 1480/2500 - Loss: 8.9863, Hour Accuracy: 0.5938, Minute Accuracy: 0.4062\n",
      "Batch 1490/2500 - Loss: 8.0976, Hour Accuracy: 0.6250, Minute Accuracy: 0.3750\n",
      "Batch 1500/2500 - Loss: 8.8683, Hour Accuracy: 0.5312, Minute Accuracy: 0.3125\n",
      "Batch 1510/2500 - Loss: 6.8677, Hour Accuracy: 0.5312, Minute Accuracy: 0.5625\n",
      "Batch 1520/2500 - Loss: 8.8405, Hour Accuracy: 0.4062, Minute Accuracy: 0.1562\n",
      "Batch 1530/2500 - Loss: 8.0801, Hour Accuracy: 0.4688, Minute Accuracy: 0.2500\n",
      "Batch 1540/2500 - Loss: 8.0637, Hour Accuracy: 0.4375, Minute Accuracy: 0.3750\n",
      "Batch 1550/2500 - Loss: 7.9082, Hour Accuracy: 0.3125, Minute Accuracy: 0.2188\n",
      "Batch 1560/2500 - Loss: 8.3294, Hour Accuracy: 0.3438, Minute Accuracy: 0.2812\n",
      "Batch 1570/2500 - Loss: 7.9715, Hour Accuracy: 0.5000, Minute Accuracy: 0.2812\n",
      "Batch 1580/2500 - Loss: 9.1909, Hour Accuracy: 0.3750, Minute Accuracy: 0.3750\n",
      "Batch 1590/2500 - Loss: 7.0513, Hour Accuracy: 0.5938, Minute Accuracy: 0.4375\n",
      "Batch 1600/2500 - Loss: 7.1406, Hour Accuracy: 0.5625, Minute Accuracy: 0.3438\n",
      "Batch 1610/2500 - Loss: 8.5472, Hour Accuracy: 0.3125, Minute Accuracy: 0.3438\n",
      "Batch 1620/2500 - Loss: 7.8780, Hour Accuracy: 0.6562, Minute Accuracy: 0.4062\n",
      "Batch 1630/2500 - Loss: 7.8439, Hour Accuracy: 0.5000, Minute Accuracy: 0.1562\n",
      "Batch 1640/2500 - Loss: 8.0256, Hour Accuracy: 0.5312, Minute Accuracy: 0.3438\n",
      "Batch 1650/2500 - Loss: 6.6766, Hour Accuracy: 0.4688, Minute Accuracy: 0.2500\n",
      "Batch 1660/2500 - Loss: 7.8697, Hour Accuracy: 0.5625, Minute Accuracy: 0.4062\n",
      "Batch 1670/2500 - Loss: 7.5571, Hour Accuracy: 0.5938, Minute Accuracy: 0.2812\n",
      "Batch 1680/2500 - Loss: 7.9560, Hour Accuracy: 0.5625, Minute Accuracy: 0.3438\n",
      "Batch 1690/2500 - Loss: 7.5174, Hour Accuracy: 0.5312, Minute Accuracy: 0.3750\n",
      "Batch 1700/2500 - Loss: 7.9447, Hour Accuracy: 0.4688, Minute Accuracy: 0.4062\n",
      "Batch 1710/2500 - Loss: 7.3599, Hour Accuracy: 0.5938, Minute Accuracy: 0.4375\n",
      "Batch 1720/2500 - Loss: 8.4120, Hour Accuracy: 0.5625, Minute Accuracy: 0.4062\n",
      "Batch 1730/2500 - Loss: 7.0397, Hour Accuracy: 0.5312, Minute Accuracy: 0.4062\n",
      "Batch 1740/2500 - Loss: 8.7606, Hour Accuracy: 0.5625, Minute Accuracy: 0.3125\n",
      "Batch 1750/2500 - Loss: 7.6691, Hour Accuracy: 0.5938, Minute Accuracy: 0.2188\n",
      "Batch 1760/2500 - Loss: 7.6069, Hour Accuracy: 0.6250, Minute Accuracy: 0.2188\n",
      "Batch 1770/2500 - Loss: 7.5131, Hour Accuracy: 0.6875, Minute Accuracy: 0.3438\n",
      "Batch 1780/2500 - Loss: 7.3444, Hour Accuracy: 0.4375, Minute Accuracy: 0.4375\n",
      "Batch 1790/2500 - Loss: 6.9207, Hour Accuracy: 0.5625, Minute Accuracy: 0.4062\n",
      "Batch 1800/2500 - Loss: 6.8893, Hour Accuracy: 0.6250, Minute Accuracy: 0.4375\n",
      "Batch 1810/2500 - Loss: 7.9908, Hour Accuracy: 0.5938, Minute Accuracy: 0.2500\n",
      "Batch 1820/2500 - Loss: 7.3048, Hour Accuracy: 0.5938, Minute Accuracy: 0.3438\n",
      "Batch 1830/2500 - Loss: 7.8112, Hour Accuracy: 0.6250, Minute Accuracy: 0.2500\n",
      "Batch 1840/2500 - Loss: 7.0264, Hour Accuracy: 0.6562, Minute Accuracy: 0.5312\n",
      "Batch 1850/2500 - Loss: 7.8261, Hour Accuracy: 0.5312, Minute Accuracy: 0.4375\n",
      "Batch 1860/2500 - Loss: 6.8539, Hour Accuracy: 0.4375, Minute Accuracy: 0.3438\n",
      "Batch 1870/2500 - Loss: 7.8290, Hour Accuracy: 0.4375, Minute Accuracy: 0.2188\n",
      "Batch 1880/2500 - Loss: 6.3903, Hour Accuracy: 0.8438, Minute Accuracy: 0.4688\n",
      "Batch 1890/2500 - Loss: 6.7543, Hour Accuracy: 0.6562, Minute Accuracy: 0.5000\n",
      "Batch 1900/2500 - Loss: 6.9979, Hour Accuracy: 0.5938, Minute Accuracy: 0.5000\n",
      "Batch 1910/2500 - Loss: 6.6269, Hour Accuracy: 0.5938, Minute Accuracy: 0.4062\n",
      "Batch 1920/2500 - Loss: 6.7158, Hour Accuracy: 0.5938, Minute Accuracy: 0.3438\n",
      "Batch 1930/2500 - Loss: 6.9559, Hour Accuracy: 0.5938, Minute Accuracy: 0.4062\n",
      "Batch 1940/2500 - Loss: 6.9633, Hour Accuracy: 0.6562, Minute Accuracy: 0.5625\n",
      "Batch 1950/2500 - Loss: 7.0946, Hour Accuracy: 0.5625, Minute Accuracy: 0.4375\n",
      "Batch 1960/2500 - Loss: 7.2285, Hour Accuracy: 0.5312, Minute Accuracy: 0.3125\n",
      "Batch 1970/2500 - Loss: 6.9992, Hour Accuracy: 0.5312, Minute Accuracy: 0.4375\n",
      "Batch 1980/2500 - Loss: 6.7619, Hour Accuracy: 0.6250, Minute Accuracy: 0.4688\n",
      "Batch 1990/2500 - Loss: 6.7791, Hour Accuracy: 0.6250, Minute Accuracy: 0.4062\n",
      "Batch 2000/2500 - Loss: 8.4522, Hour Accuracy: 0.7188, Minute Accuracy: 0.3438\n",
      "Batch 2010/2500 - Loss: 6.9803, Hour Accuracy: 0.5625, Minute Accuracy: 0.5000\n",
      "Batch 2020/2500 - Loss: 6.8538, Hour Accuracy: 0.5312, Minute Accuracy: 0.4375\n",
      "Batch 2030/2500 - Loss: 6.9270, Hour Accuracy: 0.5938, Minute Accuracy: 0.4375\n",
      "Batch 2040/2500 - Loss: 7.2066, Hour Accuracy: 0.5625, Minute Accuracy: 0.3125\n",
      "Batch 2050/2500 - Loss: 7.5060, Hour Accuracy: 0.5625, Minute Accuracy: 0.3125\n",
      "Batch 2060/2500 - Loss: 6.6398, Hour Accuracy: 0.6250, Minute Accuracy: 0.4062\n",
      "Batch 2070/2500 - Loss: 6.6716, Hour Accuracy: 0.4688, Minute Accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2080/2500 - Loss: 5.9176, Hour Accuracy: 0.6562, Minute Accuracy: 0.5000\n",
      "Batch 2090/2500 - Loss: 7.6817, Hour Accuracy: 0.4688, Minute Accuracy: 0.4375\n",
      "Batch 2100/2500 - Loss: 6.7606, Hour Accuracy: 0.6562, Minute Accuracy: 0.5000\n",
      "Batch 2110/2500 - Loss: 7.3670, Hour Accuracy: 0.5938, Minute Accuracy: 0.3750\n",
      "Batch 2120/2500 - Loss: 5.8851, Hour Accuracy: 0.7188, Minute Accuracy: 0.5938\n",
      "Batch 2130/2500 - Loss: 6.7397, Hour Accuracy: 0.5312, Minute Accuracy: 0.4062\n",
      "Batch 2140/2500 - Loss: 6.9214, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 2150/2500 - Loss: 7.1479, Hour Accuracy: 0.7188, Minute Accuracy: 0.5625\n",
      "Batch 2160/2500 - Loss: 7.2542, Hour Accuracy: 0.5000, Minute Accuracy: 0.2812\n",
      "Batch 2170/2500 - Loss: 7.9994, Hour Accuracy: 0.4688, Minute Accuracy: 0.3438\n",
      "Batch 2180/2500 - Loss: 7.5007, Hour Accuracy: 0.4688, Minute Accuracy: 0.4375\n",
      "Batch 2190/2500 - Loss: 7.0131, Hour Accuracy: 0.7188, Minute Accuracy: 0.5625\n",
      "Batch 2200/2500 - Loss: 5.9045, Hour Accuracy: 0.5938, Minute Accuracy: 0.5312\n",
      "Batch 2210/2500 - Loss: 6.2398, Hour Accuracy: 0.7500, Minute Accuracy: 0.4688\n",
      "Batch 2220/2500 - Loss: 6.2846, Hour Accuracy: 0.7500, Minute Accuracy: 0.5000\n",
      "Batch 2230/2500 - Loss: 7.2111, Hour Accuracy: 0.6250, Minute Accuracy: 0.4375\n",
      "Batch 2240/2500 - Loss: 6.7318, Hour Accuracy: 0.6875, Minute Accuracy: 0.4688\n",
      "Batch 2250/2500 - Loss: 6.6813, Hour Accuracy: 0.6562, Minute Accuracy: 0.4688\n",
      "Batch 2260/2500 - Loss: 7.7660, Hour Accuracy: 0.4375, Minute Accuracy: 0.2500\n",
      "Batch 2270/2500 - Loss: 7.3902, Hour Accuracy: 0.5312, Minute Accuracy: 0.3125\n",
      "Batch 2280/2500 - Loss: 6.1195, Hour Accuracy: 0.7812, Minute Accuracy: 0.6875\n",
      "Batch 2290/2500 - Loss: 7.2502, Hour Accuracy: 0.7188, Minute Accuracy: 0.5625\n",
      "Batch 2300/2500 - Loss: 6.6946, Hour Accuracy: 0.5625, Minute Accuracy: 0.4062\n",
      "Batch 2310/2500 - Loss: 6.5758, Hour Accuracy: 0.5312, Minute Accuracy: 0.5000\n",
      "Batch 2320/2500 - Loss: 7.9965, Hour Accuracy: 0.5000, Minute Accuracy: 0.4688\n",
      "Batch 2330/2500 - Loss: 6.5261, Hour Accuracy: 0.6562, Minute Accuracy: 0.6562\n",
      "Batch 2340/2500 - Loss: 6.0398, Hour Accuracy: 0.7188, Minute Accuracy: 0.5312\n",
      "Batch 2350/2500 - Loss: 6.6257, Hour Accuracy: 0.7500, Minute Accuracy: 0.3750\n",
      "Batch 2360/2500 - Loss: 6.8391, Hour Accuracy: 0.5938, Minute Accuracy: 0.3750\n",
      "Batch 2370/2500 - Loss: 6.8559, Hour Accuracy: 0.6562, Minute Accuracy: 0.4688\n",
      "Batch 2380/2500 - Loss: 7.2750, Hour Accuracy: 0.7188, Minute Accuracy: 0.4688\n",
      "Batch 2390/2500 - Loss: 6.7055, Hour Accuracy: 0.7500, Minute Accuracy: 0.5938\n",
      "Batch 2400/2500 - Loss: 6.5705, Hour Accuracy: 0.7188, Minute Accuracy: 0.4062\n",
      "Batch 2410/2500 - Loss: 8.2884, Hour Accuracy: 0.5938, Minute Accuracy: 0.3125\n",
      "Batch 2420/2500 - Loss: 6.6865, Hour Accuracy: 0.7188, Minute Accuracy: 0.4062\n",
      "Batch 2430/2500 - Loss: 6.7913, Hour Accuracy: 0.6562, Minute Accuracy: 0.2812\n",
      "Batch 2440/2500 - Loss: 6.1118, Hour Accuracy: 0.7500, Minute Accuracy: 0.4375\n",
      "Batch 2450/2500 - Loss: 6.0310, Hour Accuracy: 0.6562, Minute Accuracy: 0.4688\n",
      "Batch 2460/2500 - Loss: 6.1320, Hour Accuracy: 0.6875, Minute Accuracy: 0.5312\n",
      "Batch 2470/2500 - Loss: 6.2698, Hour Accuracy: 0.7500, Minute Accuracy: 0.5312\n",
      "Batch 2480/2500 - Loss: 6.9752, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 2490/2500 - Loss: 6.0774, Hour Accuracy: 0.5938, Minute Accuracy: 0.5000\n",
      "Evaluation on COCO - Top 1 Accuracy: 0.3019\n",
      "Evaluation on OpenImages - Top 1 Accuracy: 0.2832\n",
      "Epoch 1\n",
      "Batch 0/2500 - Loss: 6.4896, Hour Accuracy: 0.6562, Minute Accuracy: 0.4375\n",
      "Batch 10/2500 - Loss: 6.2330, Hour Accuracy: 0.6562, Minute Accuracy: 0.5312\n",
      "Batch 20/2500 - Loss: 6.4133, Hour Accuracy: 0.7500, Minute Accuracy: 0.3125\n",
      "Batch 30/2500 - Loss: 6.8901, Hour Accuracy: 0.5312, Minute Accuracy: 0.3438\n",
      "Batch 40/2500 - Loss: 6.5622, Hour Accuracy: 0.6250, Minute Accuracy: 0.5000\n",
      "Batch 50/2500 - Loss: 6.6662, Hour Accuracy: 0.8125, Minute Accuracy: 0.6562\n",
      "Batch 60/2500 - Loss: 7.0345, Hour Accuracy: 0.7812, Minute Accuracy: 0.4375\n",
      "Batch 70/2500 - Loss: 6.5160, Hour Accuracy: 0.7188, Minute Accuracy: 0.5625\n",
      "Batch 80/2500 - Loss: 6.4055, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 90/2500 - Loss: 6.2093, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 100/2500 - Loss: 6.7746, Hour Accuracy: 0.8438, Minute Accuracy: 0.7188\n",
      "Batch 110/2500 - Loss: 8.3008, Hour Accuracy: 0.5625, Minute Accuracy: 0.3750\n",
      "Batch 120/2500 - Loss: 7.9246, Hour Accuracy: 0.6875, Minute Accuracy: 0.4688\n",
      "Batch 130/2500 - Loss: 6.2983, Hour Accuracy: 0.8438, Minute Accuracy: 0.5938\n",
      "Batch 140/2500 - Loss: 6.4147, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 150/2500 - Loss: 8.0342, Hour Accuracy: 0.7812, Minute Accuracy: 0.4375\n",
      "Batch 160/2500 - Loss: 7.3912, Hour Accuracy: 0.7188, Minute Accuracy: 0.4375\n",
      "Batch 170/2500 - Loss: 6.7698, Hour Accuracy: 0.7188, Minute Accuracy: 0.5312\n",
      "Batch 180/2500 - Loss: 6.6743, Hour Accuracy: 0.7188, Minute Accuracy: 0.4375\n",
      "Batch 190/2500 - Loss: 5.5998, Hour Accuracy: 0.7188, Minute Accuracy: 0.6250\n",
      "Batch 200/2500 - Loss: 6.4799, Hour Accuracy: 0.8438, Minute Accuracy: 0.5625\n",
      "Batch 210/2500 - Loss: 6.1904, Hour Accuracy: 0.6562, Minute Accuracy: 0.5000\n",
      "Batch 220/2500 - Loss: 8.2029, Hour Accuracy: 0.5000, Minute Accuracy: 0.4062\n",
      "Batch 230/2500 - Loss: 7.3525, Hour Accuracy: 0.5938, Minute Accuracy: 0.3750\n",
      "Batch 240/2500 - Loss: 5.6075, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 250/2500 - Loss: 6.1837, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 260/2500 - Loss: 7.0162, Hour Accuracy: 0.5312, Minute Accuracy: 0.4688\n",
      "Batch 270/2500 - Loss: 6.4289, Hour Accuracy: 0.7812, Minute Accuracy: 0.5312\n",
      "Batch 280/2500 - Loss: 6.4729, Hour Accuracy: 0.6562, Minute Accuracy: 0.3125\n",
      "Batch 290/2500 - Loss: 5.4142, Hour Accuracy: 0.7812, Minute Accuracy: 0.6250\n",
      "Batch 300/2500 - Loss: 7.0034, Hour Accuracy: 0.4375, Minute Accuracy: 0.3438\n",
      "Batch 310/2500 - Loss: 6.5439, Hour Accuracy: 0.6562, Minute Accuracy: 0.4375\n",
      "Batch 320/2500 - Loss: 6.1711, Hour Accuracy: 0.6250, Minute Accuracy: 0.4375\n",
      "Batch 330/2500 - Loss: 5.6794, Hour Accuracy: 0.6250, Minute Accuracy: 0.2812\n",
      "Batch 340/2500 - Loss: 5.5595, Hour Accuracy: 0.8125, Minute Accuracy: 0.5938\n",
      "Batch 350/2500 - Loss: 6.5005, Hour Accuracy: 0.7500, Minute Accuracy: 0.6250\n",
      "Batch 360/2500 - Loss: 6.2736, Hour Accuracy: 0.7500, Minute Accuracy: 0.5000\n",
      "Batch 370/2500 - Loss: 6.8730, Hour Accuracy: 0.7500, Minute Accuracy: 0.4375\n",
      "Batch 380/2500 - Loss: 5.5876, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 390/2500 - Loss: 6.2116, Hour Accuracy: 0.7500, Minute Accuracy: 0.5000\n",
      "Batch 400/2500 - Loss: 6.1774, Hour Accuracy: 0.6875, Minute Accuracy: 0.5000\n",
      "Batch 410/2500 - Loss: 6.6122, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 420/2500 - Loss: 6.7660, Hour Accuracy: 0.7500, Minute Accuracy: 0.5312\n",
      "Batch 430/2500 - Loss: 5.7963, Hour Accuracy: 0.7500, Minute Accuracy: 0.6250\n",
      "Batch 440/2500 - Loss: 6.0075, Hour Accuracy: 0.7188, Minute Accuracy: 0.5312\n",
      "Batch 450/2500 - Loss: 5.6247, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 460/2500 - Loss: 7.3724, Hour Accuracy: 0.6562, Minute Accuracy: 0.5625\n",
      "Batch 470/2500 - Loss: 7.6133, Hour Accuracy: 0.8438, Minute Accuracy: 0.4688\n",
      "Batch 480/2500 - Loss: 5.3244, Hour Accuracy: 0.7500, Minute Accuracy: 0.4375\n",
      "Batch 490/2500 - Loss: 5.5624, Hour Accuracy: 0.7188, Minute Accuracy: 0.5000\n",
      "Batch 500/2500 - Loss: 6.4197, Hour Accuracy: 0.6250, Minute Accuracy: 0.5625\n",
      "Batch 510/2500 - Loss: 6.6543, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 520/2500 - Loss: 6.1636, Hour Accuracy: 0.5938, Minute Accuracy: 0.5625\n",
      "Batch 530/2500 - Loss: 6.4647, Hour Accuracy: 0.8125, Minute Accuracy: 0.6562\n",
      "Batch 540/2500 - Loss: 5.4977, Hour Accuracy: 0.7812, Minute Accuracy: 0.7188\n",
      "Batch 550/2500 - Loss: 6.6889, Hour Accuracy: 0.7812, Minute Accuracy: 0.5312\n",
      "Batch 560/2500 - Loss: 6.5361, Hour Accuracy: 0.5312, Minute Accuracy: 0.4062\n",
      "Batch 570/2500 - Loss: 5.2465, Hour Accuracy: 0.7500, Minute Accuracy: 0.6250\n",
      "Batch 580/2500 - Loss: 5.6085, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 590/2500 - Loss: 5.8557, Hour Accuracy: 0.8125, Minute Accuracy: 0.7188\n",
      "Batch 600/2500 - Loss: 5.0810, Hour Accuracy: 0.7812, Minute Accuracy: 0.7188\n",
      "Batch 610/2500 - Loss: 5.1276, Hour Accuracy: 0.9062, Minute Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 620/2500 - Loss: 5.5818, Hour Accuracy: 0.8438, Minute Accuracy: 0.5312\n",
      "Batch 630/2500 - Loss: 6.2032, Hour Accuracy: 0.7812, Minute Accuracy: 0.5312\n",
      "Batch 640/2500 - Loss: 6.4402, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 650/2500 - Loss: 6.7349, Hour Accuracy: 0.6875, Minute Accuracy: 0.4375\n",
      "Batch 660/2500 - Loss: 5.6140, Hour Accuracy: 0.8438, Minute Accuracy: 0.6250\n",
      "Batch 670/2500 - Loss: 5.5301, Hour Accuracy: 0.7812, Minute Accuracy: 0.5312\n",
      "Batch 680/2500 - Loss: 6.2650, Hour Accuracy: 0.7188, Minute Accuracy: 0.5625\n",
      "Batch 690/2500 - Loss: 5.4765, Hour Accuracy: 0.7188, Minute Accuracy: 0.6250\n",
      "Batch 700/2500 - Loss: 5.9461, Hour Accuracy: 0.7500, Minute Accuracy: 0.6875\n",
      "Batch 710/2500 - Loss: 7.1229, Hour Accuracy: 0.6562, Minute Accuracy: 0.5938\n",
      "Batch 720/2500 - Loss: 5.4681, Hour Accuracy: 0.9062, Minute Accuracy: 0.7500\n",
      "Batch 730/2500 - Loss: 6.5262, Hour Accuracy: 0.9062, Minute Accuracy: 0.7188\n",
      "Batch 740/2500 - Loss: 6.2379, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 750/2500 - Loss: 6.5337, Hour Accuracy: 0.9062, Minute Accuracy: 0.4688\n",
      "Batch 760/2500 - Loss: 6.4544, Hour Accuracy: 0.6250, Minute Accuracy: 0.2812\n",
      "Batch 770/2500 - Loss: 4.5232, Hour Accuracy: 0.8125, Minute Accuracy: 0.7812\n",
      "Batch 780/2500 - Loss: 6.7665, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 790/2500 - Loss: 6.2911, Hour Accuracy: 0.7188, Minute Accuracy: 0.5000\n",
      "Batch 800/2500 - Loss: 5.8365, Hour Accuracy: 0.8125, Minute Accuracy: 0.6250\n",
      "Batch 810/2500 - Loss: 5.4390, Hour Accuracy: 0.8750, Minute Accuracy: 0.7812\n",
      "Batch 820/2500 - Loss: 5.3888, Hour Accuracy: 0.8125, Minute Accuracy: 0.6875\n",
      "Batch 830/2500 - Loss: 5.7102, Hour Accuracy: 0.6562, Minute Accuracy: 0.5000\n",
      "Batch 840/2500 - Loss: 6.0225, Hour Accuracy: 0.8750, Minute Accuracy: 0.5625\n",
      "Batch 850/2500 - Loss: 5.7451, Hour Accuracy: 0.7500, Minute Accuracy: 0.6250\n",
      "Batch 860/2500 - Loss: 4.8560, Hour Accuracy: 0.8125, Minute Accuracy: 0.6875\n",
      "Batch 870/2500 - Loss: 5.9006, Hour Accuracy: 0.7188, Minute Accuracy: 0.5938\n",
      "Batch 880/2500 - Loss: 5.4638, Hour Accuracy: 0.7188, Minute Accuracy: 0.5312\n",
      "Batch 890/2500 - Loss: 6.1552, Hour Accuracy: 0.8125, Minute Accuracy: 0.5938\n",
      "Batch 900/2500 - Loss: 6.0254, Hour Accuracy: 0.8125, Minute Accuracy: 0.7500\n",
      "Batch 910/2500 - Loss: 6.2233, Hour Accuracy: 0.7500, Minute Accuracy: 0.7500\n",
      "Batch 920/2500 - Loss: 5.8860, Hour Accuracy: 0.6562, Minute Accuracy: 0.6250\n",
      "Batch 930/2500 - Loss: 5.8518, Hour Accuracy: 0.7500, Minute Accuracy: 0.6250\n",
      "Batch 940/2500 - Loss: 5.7712, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 950/2500 - Loss: 5.1680, Hour Accuracy: 0.8750, Minute Accuracy: 0.6562\n",
      "Batch 960/2500 - Loss: 5.2727, Hour Accuracy: 0.8750, Minute Accuracy: 0.7188\n",
      "Batch 970/2500 - Loss: 6.2885, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 980/2500 - Loss: 5.5960, Hour Accuracy: 0.8750, Minute Accuracy: 0.7188\n",
      "Batch 990/2500 - Loss: 6.1046, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 1000/2500 - Loss: 6.2639, Hour Accuracy: 0.6875, Minute Accuracy: 0.7812\n",
      "Batch 1010/2500 - Loss: 6.7247, Hour Accuracy: 0.6562, Minute Accuracy: 0.3438\n",
      "Batch 1020/2500 - Loss: 5.9951, Hour Accuracy: 0.9062, Minute Accuracy: 0.5938\n",
      "Batch 1030/2500 - Loss: 4.6644, Hour Accuracy: 0.8438, Minute Accuracy: 0.7188\n",
      "Batch 1040/2500 - Loss: 6.1597, Hour Accuracy: 0.7188, Minute Accuracy: 0.4375\n",
      "Batch 1050/2500 - Loss: 6.5939, Hour Accuracy: 0.6875, Minute Accuracy: 0.5000\n",
      "Batch 1060/2500 - Loss: 5.7208, Hour Accuracy: 0.5000, Minute Accuracy: 0.5625\n",
      "Batch 1070/2500 - Loss: 4.8134, Hour Accuracy: 0.8750, Minute Accuracy: 0.7812\n",
      "Batch 1080/2500 - Loss: 5.4823, Hour Accuracy: 0.7188, Minute Accuracy: 0.5312\n",
      "Batch 1090/2500 - Loss: 6.5031, Hour Accuracy: 0.7188, Minute Accuracy: 0.5938\n",
      "Batch 1100/2500 - Loss: 5.8020, Hour Accuracy: 0.7500, Minute Accuracy: 0.5938\n",
      "Batch 1110/2500 - Loss: 6.2671, Hour Accuracy: 0.7188, Minute Accuracy: 0.5938\n",
      "Batch 1120/2500 - Loss: 6.4569, Hour Accuracy: 0.7812, Minute Accuracy: 0.4688\n",
      "Batch 1130/2500 - Loss: 5.2278, Hour Accuracy: 0.8438, Minute Accuracy: 0.6250\n",
      "Batch 1140/2500 - Loss: 5.8394, Hour Accuracy: 0.8125, Minute Accuracy: 0.6875\n",
      "Batch 1150/2500 - Loss: 5.7703, Hour Accuracy: 0.6875, Minute Accuracy: 0.5625\n",
      "Batch 1160/2500 - Loss: 6.5362, Hour Accuracy: 0.7812, Minute Accuracy: 0.5000\n",
      "Batch 1170/2500 - Loss: 5.3447, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 1180/2500 - Loss: 5.3307, Hour Accuracy: 0.8438, Minute Accuracy: 0.7812\n",
      "Batch 1190/2500 - Loss: 6.1410, Hour Accuracy: 0.8125, Minute Accuracy: 0.5000\n",
      "Batch 1200/2500 - Loss: 5.7759, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 1210/2500 - Loss: 5.6930, Hour Accuracy: 0.8125, Minute Accuracy: 0.5000\n",
      "Batch 1220/2500 - Loss: 6.2450, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 1230/2500 - Loss: 5.1403, Hour Accuracy: 0.8438, Minute Accuracy: 0.5938\n",
      "Batch 1240/2500 - Loss: 7.3789, Hour Accuracy: 0.6562, Minute Accuracy: 0.6250\n",
      "Batch 1250/2500 - Loss: 5.5627, Hour Accuracy: 0.8438, Minute Accuracy: 0.6875\n",
      "Batch 1260/2500 - Loss: 6.2629, Hour Accuracy: 0.6875, Minute Accuracy: 0.4375\n",
      "Batch 1270/2500 - Loss: 6.0795, Hour Accuracy: 0.7188, Minute Accuracy: 0.5625\n",
      "Batch 1280/2500 - Loss: 5.2977, Hour Accuracy: 0.8125, Minute Accuracy: 0.7188\n",
      "Batch 1290/2500 - Loss: 6.2968, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 1300/2500 - Loss: 4.4686, Hour Accuracy: 0.9375, Minute Accuracy: 0.9062\n",
      "Batch 1310/2500 - Loss: 6.1285, Hour Accuracy: 0.7812, Minute Accuracy: 0.6250\n",
      "Batch 1320/2500 - Loss: 4.9508, Hour Accuracy: 0.9062, Minute Accuracy: 0.4375\n",
      "Batch 1330/2500 - Loss: 5.6539, Hour Accuracy: 0.6875, Minute Accuracy: 0.6562\n",
      "Batch 1340/2500 - Loss: 5.0660, Hour Accuracy: 0.8125, Minute Accuracy: 0.6875\n",
      "Batch 1350/2500 - Loss: 5.7549, Hour Accuracy: 0.8438, Minute Accuracy: 0.4688\n",
      "Batch 1360/2500 - Loss: 7.1277, Hour Accuracy: 0.7812, Minute Accuracy: 0.5000\n",
      "Batch 1370/2500 - Loss: 5.7221, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 1380/2500 - Loss: 5.3627, Hour Accuracy: 0.8750, Minute Accuracy: 0.7188\n",
      "Batch 1390/2500 - Loss: 5.8124, Hour Accuracy: 0.8750, Minute Accuracy: 0.5938\n",
      "Batch 1400/2500 - Loss: 5.1379, Hour Accuracy: 0.9375, Minute Accuracy: 0.7500\n",
      "Batch 1410/2500 - Loss: 5.7047, Hour Accuracy: 0.9062, Minute Accuracy: 0.5938\n",
      "Batch 1420/2500 - Loss: 4.7055, Hour Accuracy: 0.8125, Minute Accuracy: 0.8125\n",
      "Batch 1430/2500 - Loss: 4.5033, Hour Accuracy: 0.8438, Minute Accuracy: 0.7188\n",
      "Batch 1440/2500 - Loss: 5.5757, Hour Accuracy: 0.6875, Minute Accuracy: 0.5000\n",
      "Batch 1450/2500 - Loss: 5.5351, Hour Accuracy: 0.7812, Minute Accuracy: 0.7812\n",
      "Batch 1460/2500 - Loss: 5.2168, Hour Accuracy: 0.8750, Minute Accuracy: 0.7812\n",
      "Batch 1470/2500 - Loss: 6.1360, Hour Accuracy: 0.7500, Minute Accuracy: 0.5000\n",
      "Batch 1480/2500 - Loss: 5.1491, Hour Accuracy: 0.8125, Minute Accuracy: 0.5625\n",
      "Batch 1490/2500 - Loss: 5.1225, Hour Accuracy: 0.8438, Minute Accuracy: 0.8125\n",
      "Batch 1500/2500 - Loss: 4.6189, Hour Accuracy: 0.8750, Minute Accuracy: 0.7188\n",
      "Batch 1510/2500 - Loss: 5.1183, Hour Accuracy: 0.8125, Minute Accuracy: 0.6875\n",
      "Batch 1520/2500 - Loss: 5.6132, Hour Accuracy: 0.8750, Minute Accuracy: 0.8438\n",
      "Batch 1530/2500 - Loss: 5.1453, Hour Accuracy: 0.7812, Minute Accuracy: 0.6562\n",
      "Batch 1540/2500 - Loss: 6.1137, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 1550/2500 - Loss: 5.3456, Hour Accuracy: 0.8438, Minute Accuracy: 0.8125\n",
      "Batch 1560/2500 - Loss: 4.8927, Hour Accuracy: 0.7500, Minute Accuracy: 0.6875\n",
      "Batch 1570/2500 - Loss: 5.7572, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 1580/2500 - Loss: 5.8891, Hour Accuracy: 0.8438, Minute Accuracy: 0.6562\n",
      "Batch 1590/2500 - Loss: 5.6311, Hour Accuracy: 0.8438, Minute Accuracy: 0.7188\n",
      "Batch 1600/2500 - Loss: 5.0307, Hour Accuracy: 0.8750, Minute Accuracy: 0.6562\n",
      "Batch 1610/2500 - Loss: 4.8209, Hour Accuracy: 0.7812, Minute Accuracy: 0.6875\n",
      "Batch 1620/2500 - Loss: 4.9764, Hour Accuracy: 0.9062, Minute Accuracy: 0.6875\n",
      "Batch 1630/2500 - Loss: 5.2522, Hour Accuracy: 0.8125, Minute Accuracy: 0.5625\n",
      "Batch 1640/2500 - Loss: 6.4654, Hour Accuracy: 0.6562, Minute Accuracy: 0.5625\n",
      "Batch 1650/2500 - Loss: 5.0224, Hour Accuracy: 0.8438, Minute Accuracy: 0.5312\n",
      "Batch 1660/2500 - Loss: 5.0648, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1670/2500 - Loss: 5.1963, Hour Accuracy: 0.7500, Minute Accuracy: 0.8125\n",
      "Batch 1680/2500 - Loss: 5.7830, Hour Accuracy: 0.7500, Minute Accuracy: 0.4062\n",
      "Batch 1690/2500 - Loss: 5.5255, Hour Accuracy: 1.0000, Minute Accuracy: 0.8125\n",
      "Batch 1700/2500 - Loss: 5.9635, Hour Accuracy: 0.8438, Minute Accuracy: 0.5625\n",
      "Batch 1710/2500 - Loss: 5.0869, Hour Accuracy: 0.9062, Minute Accuracy: 0.5938\n",
      "Batch 1720/2500 - Loss: 5.8914, Hour Accuracy: 0.7812, Minute Accuracy: 0.5000\n",
      "Batch 1730/2500 - Loss: 5.6353, Hour Accuracy: 0.8125, Minute Accuracy: 0.5312\n",
      "Batch 1740/2500 - Loss: 6.2918, Hour Accuracy: 0.7500, Minute Accuracy: 0.5000\n",
      "Batch 1750/2500 - Loss: 6.1363, Hour Accuracy: 0.7812, Minute Accuracy: 0.5312\n",
      "Batch 1760/2500 - Loss: 4.9717, Hour Accuracy: 0.9688, Minute Accuracy: 0.8750\n",
      "Batch 1770/2500 - Loss: 5.4347, Hour Accuracy: 0.8438, Minute Accuracy: 0.6875\n",
      "Batch 1780/2500 - Loss: 5.1762, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 1790/2500 - Loss: 6.2866, Hour Accuracy: 0.7812, Minute Accuracy: 0.5938\n",
      "Batch 1800/2500 - Loss: 5.1517, Hour Accuracy: 0.8125, Minute Accuracy: 0.7188\n",
      "Batch 1810/2500 - Loss: 7.0175, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 1820/2500 - Loss: 6.0254, Hour Accuracy: 0.7812, Minute Accuracy: 0.6875\n",
      "Batch 1830/2500 - Loss: 4.6652, Hour Accuracy: 0.7188, Minute Accuracy: 0.6250\n",
      "Batch 1840/2500 - Loss: 4.4432, Hour Accuracy: 0.9062, Minute Accuracy: 0.8438\n",
      "Batch 1850/2500 - Loss: 6.3343, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 1860/2500 - Loss: 4.6381, Hour Accuracy: 0.8438, Minute Accuracy: 0.6562\n",
      "Batch 1870/2500 - Loss: 5.0130, Hour Accuracy: 0.8438, Minute Accuracy: 0.6562\n",
      "Batch 1880/2500 - Loss: 5.3137, Hour Accuracy: 0.8125, Minute Accuracy: 0.5938\n",
      "Batch 1890/2500 - Loss: 5.4337, Hour Accuracy: 0.8125, Minute Accuracy: 0.7188\n",
      "Batch 1900/2500 - Loss: 5.6674, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 1910/2500 - Loss: 4.9258, Hour Accuracy: 0.9062, Minute Accuracy: 0.6875\n",
      "Batch 1920/2500 - Loss: 4.8385, Hour Accuracy: 0.7500, Minute Accuracy: 0.6875\n",
      "Batch 1930/2500 - Loss: 5.3666, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 1940/2500 - Loss: 5.6506, Hour Accuracy: 0.6875, Minute Accuracy: 0.6562\n",
      "Batch 1950/2500 - Loss: 4.7555, Hour Accuracy: 0.8125, Minute Accuracy: 0.6250\n",
      "Batch 1960/2500 - Loss: 4.7477, Hour Accuracy: 0.8750, Minute Accuracy: 0.7188\n",
      "Batch 1970/2500 - Loss: 6.3017, Hour Accuracy: 0.7188, Minute Accuracy: 0.5938\n",
      "Batch 1980/2500 - Loss: 5.1217, Hour Accuracy: 0.8125, Minute Accuracy: 0.6250\n",
      "Batch 1990/2500 - Loss: 5.8999, Hour Accuracy: 0.7812, Minute Accuracy: 0.4375\n",
      "Batch 2000/2500 - Loss: 5.0200, Hour Accuracy: 0.7812, Minute Accuracy: 0.6562\n",
      "Batch 2010/2500 - Loss: 5.8241, Hour Accuracy: 0.8750, Minute Accuracy: 0.6875\n",
      "Batch 2020/2500 - Loss: 6.2528, Hour Accuracy: 0.6875, Minute Accuracy: 0.5625\n",
      "Batch 2030/2500 - Loss: 4.7002, Hour Accuracy: 0.9688, Minute Accuracy: 0.8125\n",
      "Batch 2040/2500 - Loss: 4.3453, Hour Accuracy: 0.9688, Minute Accuracy: 0.7812\n",
      "Batch 2050/2500 - Loss: 5.3065, Hour Accuracy: 0.7812, Minute Accuracy: 0.7500\n",
      "Batch 2060/2500 - Loss: 5.7597, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 2070/2500 - Loss: 5.4831, Hour Accuracy: 0.7500, Minute Accuracy: 0.6562\n",
      "Batch 2080/2500 - Loss: 5.1931, Hour Accuracy: 0.9375, Minute Accuracy: 0.8438\n",
      "Batch 2090/2500 - Loss: 6.2465, Hour Accuracy: 0.8750, Minute Accuracy: 0.7500\n",
      "Batch 2100/2500 - Loss: 6.3337, Hour Accuracy: 0.7500, Minute Accuracy: 0.5625\n",
      "Batch 2110/2500 - Loss: 4.9866, Hour Accuracy: 0.8750, Minute Accuracy: 0.7188\n",
      "Batch 2120/2500 - Loss: 4.6960, Hour Accuracy: 0.8750, Minute Accuracy: 0.7500\n",
      "Batch 2130/2500 - Loss: 5.8909, Hour Accuracy: 0.8125, Minute Accuracy: 0.5000\n",
      "Batch 2140/2500 - Loss: 6.2499, Hour Accuracy: 0.7500, Minute Accuracy: 0.6250\n",
      "Batch 2150/2500 - Loss: 4.7805, Hour Accuracy: 0.8750, Minute Accuracy: 0.6562\n",
      "Batch 2160/2500 - Loss: 4.8300, Hour Accuracy: 0.7500, Minute Accuracy: 0.7500\n",
      "Batch 2170/2500 - Loss: 4.6282, Hour Accuracy: 0.8750, Minute Accuracy: 0.8438\n",
      "Batch 2180/2500 - Loss: 6.2046, Hour Accuracy: 0.7812, Minute Accuracy: 0.7188\n",
      "Batch 2190/2500 - Loss: 4.1081, Hour Accuracy: 0.9375, Minute Accuracy: 0.8125\n",
      "Batch 2200/2500 - Loss: 4.9185, Hour Accuracy: 0.8125, Minute Accuracy: 0.7500\n",
      "Batch 2210/2500 - Loss: 5.4199, Hour Accuracy: 0.9062, Minute Accuracy: 0.7812\n",
      "Batch 2220/2500 - Loss: 5.2014, Hour Accuracy: 0.9062, Minute Accuracy: 0.6875\n",
      "Batch 2230/2500 - Loss: 5.2343, Hour Accuracy: 0.8125, Minute Accuracy: 0.7188\n",
      "Batch 2240/2500 - Loss: 4.1661, Hour Accuracy: 0.8438, Minute Accuracy: 0.6875\n",
      "Batch 2250/2500 - Loss: 4.9041, Hour Accuracy: 0.6875, Minute Accuracy: 0.7188\n",
      "Batch 2260/2500 - Loss: 5.0025, Hour Accuracy: 0.8438, Minute Accuracy: 0.6562\n",
      "Batch 2270/2500 - Loss: 4.6468, Hour Accuracy: 0.8438, Minute Accuracy: 0.7500\n",
      "Batch 2280/2500 - Loss: 5.7443, Hour Accuracy: 0.7500, Minute Accuracy: 0.7188\n",
      "Batch 2290/2500 - Loss: 5.2568, Hour Accuracy: 0.8125, Minute Accuracy: 0.7812\n",
      "Batch 2300/2500 - Loss: 5.0698, Hour Accuracy: 0.7812, Minute Accuracy: 0.6875\n",
      "Batch 2310/2500 - Loss: 6.3914, Hour Accuracy: 0.8125, Minute Accuracy: 0.6562\n",
      "Batch 2320/2500 - Loss: 4.6190, Hour Accuracy: 0.8125, Minute Accuracy: 0.7812\n",
      "Batch 2330/2500 - Loss: 5.1938, Hour Accuracy: 0.7188, Minute Accuracy: 0.6875\n",
      "Batch 2340/2500 - Loss: 4.6472, Hour Accuracy: 0.8750, Minute Accuracy: 0.8750\n",
      "Batch 2350/2500 - Loss: 5.7987, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 2360/2500 - Loss: 5.4589, Hour Accuracy: 0.8438, Minute Accuracy: 0.6562\n",
      "Batch 2370/2500 - Loss: 4.6331, Hour Accuracy: 0.7812, Minute Accuracy: 0.7500\n",
      "Batch 2380/2500 - Loss: 5.6641, Hour Accuracy: 0.7188, Minute Accuracy: 0.5625\n",
      "Batch 2390/2500 - Loss: 4.8242, Hour Accuracy: 0.8125, Minute Accuracy: 0.5938\n",
      "Batch 2400/2500 - Loss: 5.8483, Hour Accuracy: 0.7812, Minute Accuracy: 0.5625\n",
      "Batch 2410/2500 - Loss: 5.0387, Hour Accuracy: 0.9062, Minute Accuracy: 0.6875\n",
      "Batch 2420/2500 - Loss: 5.0826, Hour Accuracy: 0.7812, Minute Accuracy: 0.7500\n",
      "Batch 2430/2500 - Loss: 6.1484, Hour Accuracy: 0.6875, Minute Accuracy: 0.5000\n",
      "Batch 2440/2500 - Loss: 4.5755, Hour Accuracy: 0.8438, Minute Accuracy: 0.7812\n",
      "Batch 2450/2500 - Loss: 4.7548, Hour Accuracy: 0.8750, Minute Accuracy: 0.7188\n",
      "Batch 2460/2500 - Loss: 4.3612, Hour Accuracy: 0.9375, Minute Accuracy: 0.9062\n",
      "Batch 2470/2500 - Loss: 4.8195, Hour Accuracy: 1.0000, Minute Accuracy: 0.8438\n",
      "Batch 2480/2500 - Loss: 6.4544, Hour Accuracy: 0.8125, Minute Accuracy: 0.6562\n",
      "Batch 2490/2500 - Loss: 5.2625, Hour Accuracy: 0.9375, Minute Accuracy: 0.7500\n",
      "Evaluation on COCO - Top 1 Accuracy: 0.3626\n",
      "Evaluation on OpenImages - Top 1 Accuracy: 0.3356\n",
      "Epoch 2\n",
      "Batch 0/2500 - Loss: 4.9858, Hour Accuracy: 0.8125, Minute Accuracy: 0.7500\n",
      "Batch 10/2500 - Loss: 5.4132, Hour Accuracy: 0.8125, Minute Accuracy: 0.7188\n",
      "Batch 20/2500 - Loss: 5.6255, Hour Accuracy: 0.7812, Minute Accuracy: 0.6875\n",
      "Batch 30/2500 - Loss: 4.9234, Hour Accuracy: 0.8125, Minute Accuracy: 0.5312\n",
      "Batch 40/2500 - Loss: 5.3056, Hour Accuracy: 0.8438, Minute Accuracy: 0.5938\n",
      "Batch 50/2500 - Loss: 5.3003, Hour Accuracy: 0.8125, Minute Accuracy: 0.6875\n",
      "Batch 60/2500 - Loss: 6.0224, Hour Accuracy: 0.8125, Minute Accuracy: 0.6250\n",
      "Batch 70/2500 - Loss: 4.3706, Hour Accuracy: 0.9062, Minute Accuracy: 0.6875\n",
      "Batch 80/2500 - Loss: 4.8110, Hour Accuracy: 0.9375, Minute Accuracy: 0.9688\n",
      "Batch 90/2500 - Loss: 4.8412, Hour Accuracy: 0.8438, Minute Accuracy: 0.7812\n",
      "Batch 100/2500 - Loss: 5.6100, Hour Accuracy: 0.6875, Minute Accuracy: 0.7188\n",
      "Batch 110/2500 - Loss: 5.9462, Hour Accuracy: 0.7500, Minute Accuracy: 0.7188\n",
      "Batch 120/2500 - Loss: 4.0008, Hour Accuracy: 0.9062, Minute Accuracy: 0.7500\n",
      "Batch 130/2500 - Loss: 4.9328, Hour Accuracy: 0.7812, Minute Accuracy: 0.5312\n",
      "Batch 140/2500 - Loss: 7.0638, Hour Accuracy: 0.6562, Minute Accuracy: 0.5625\n",
      "Batch 150/2500 - Loss: 4.9619, Hour Accuracy: 0.8438, Minute Accuracy: 0.6875\n",
      "Batch 160/2500 - Loss: 5.4337, Hour Accuracy: 0.7188, Minute Accuracy: 0.5312\n",
      "Batch 170/2500 - Loss: 4.8110, Hour Accuracy: 0.8125, Minute Accuracy: 0.8125\n",
      "Batch 180/2500 - Loss: 4.9980, Hour Accuracy: 0.9062, Minute Accuracy: 0.8125\n",
      "Batch 190/2500 - Loss: 5.9780, Hour Accuracy: 0.7812, Minute Accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/2500 - Loss: 4.9379, Hour Accuracy: 0.9062, Minute Accuracy: 0.7188\n",
      "Batch 210/2500 - Loss: 4.2310, Hour Accuracy: 0.8438, Minute Accuracy: 0.7812\n",
      "Batch 220/2500 - Loss: 4.5686, Hour Accuracy: 0.9062, Minute Accuracy: 0.6875\n",
      "Batch 230/2500 - Loss: 4.9128, Hour Accuracy: 0.8125, Minute Accuracy: 0.6562\n",
      "Batch 240/2500 - Loss: 4.6539, Hour Accuracy: 0.7500, Minute Accuracy: 0.5938\n",
      "Batch 250/2500 - Loss: 4.1944, Hour Accuracy: 0.9688, Minute Accuracy: 0.7812\n",
      "Batch 260/2500 - Loss: 5.3547, Hour Accuracy: 0.7812, Minute Accuracy: 0.6250\n",
      "Batch 270/2500 - Loss: 4.8076, Hour Accuracy: 0.9062, Minute Accuracy: 0.6562\n",
      "Batch 280/2500 - Loss: 4.5734, Hour Accuracy: 0.8438, Minute Accuracy: 0.8750\n",
      "Batch 290/2500 - Loss: 4.2426, Hour Accuracy: 0.9375, Minute Accuracy: 0.8750\n",
      "Batch 300/2500 - Loss: 5.7592, Hour Accuracy: 0.8750, Minute Accuracy: 0.6562\n",
      "Batch 310/2500 - Loss: 4.5656, Hour Accuracy: 0.9062, Minute Accuracy: 0.9062\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import einops\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from data import *\n",
    "from utils import warp, update_train_log, write_train_log, update_eval_log, write_eval_log\n",
    "\n",
    "def main(args):\n",
    "    bsz = 32\n",
    "    lr = 1e-4\n",
    "    verbose = args.verbose\n",
    "    use_stn = not args.no_stn\n",
    "    augment = not args.no_augment\n",
    "    homography = not args.no_homography\n",
    "    artefacts = not args.no_artefacts\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    dt_string = datetime.now().strftime(\"%m_%d_%H_%M\")\n",
    "    writer = SummaryWriter(logdir='../logs/{}-{}'.format(dt_string, verbose))\n",
    "\n",
    "    # DATASET\n",
    "    trn_dataset = ClockSyn(augment=augment, use_homography=homography, use_artefacts=artefacts)\n",
    "    coco_dataset = ClockEval('coco')\n",
    "    openimg_dataset = ClockEval('openimages')\n",
    "    trn_loader = DataLoader(trn_dataset, batch_size=bsz, shuffle=True, num_workers=4)\n",
    "    coco_loader = DataLoader(coco_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "    openimg_loader = DataLoader(openimg_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "    # MODEL\n",
    "    model_stn = models.resnet50(pretrained=True)\n",
    "    model_stn.fc = nn.Linear(2048, 8)\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(2048, 720)\n",
    "    if args.resume_path:\n",
    "        model.load_state_dict(torch.load(args.resume_path))\n",
    "        model_stn.load_state_dict(torch.load(args.stn_resume_path))\n",
    "    model_stn.to(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # OPTIMIZER\n",
    "    optimizer = optim.Adam(list(model.parameters()) + list(model_stn.parameters()), lr=lr)\n",
    "    cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    for ep in range(40):\n",
    "        print('Epoch {}'.format(ep))\n",
    "        train_log = {'loss_cls': [], 'loss_reg': [], 'hour_acc': [], 'minute_acc': []}\n",
    "\n",
    "        for i, trn_sample in enumerate(trn_loader):\n",
    "            model.train()\n",
    "            model_stn.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            img, hour, minute, Minv = trn_sample\n",
    "            img = img.float().to(device)\n",
    "            Minv = Minv.to(device)\n",
    "            hour = hour.type(torch.long).to(device)\n",
    "            minute = minute.type(torch.long).to(device)\n",
    "\n",
    "            # PREDICT\n",
    "            with autocast():\n",
    "                if use_stn:\n",
    "                    pred_st = model_stn(img)\n",
    "                    pred_st = torch.cat([pred_st, torch.ones(bsz, 1).to(device)], 1)\n",
    "                    Minv_pred = torch.reshape(pred_st, (-1, 3, 3))\n",
    "                    img_ = warp(img, Minv_pred)\n",
    "                    if random.random() < 0.5:\n",
    "                        pred = model(img_)\n",
    "                    else:\n",
    "                        pred = model(img)\n",
    "                    loss_reg = torch.mean(torch.abs((Minv.reshape(bsz, 9) - pred_st)))\n",
    "                    loss_cls = cross_entropy(pred, hour * 60 + minute)\n",
    "                else:\n",
    "                    pred = model(img)\n",
    "                    loss_cls = cross_entropy(pred, hour * 60 + minute)\n",
    "                    loss_reg = 0.\n",
    "\n",
    "                # LOSS\n",
    "                loss = 100 * loss_reg + loss_cls\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # METRIC\n",
    "            max_pred = torch.argsort(pred, dim=1, descending=True)\n",
    "            max_pred = max_pred[:, 0]\n",
    "            max_h = max_pred // 60\n",
    "            max_m = max_pred % 60\n",
    "            hour_acc = float(torch.sum(max_h == hour)) / bsz\n",
    "            minute_acc = float(torch.sum(torch.abs(max_m - minute) <= 1)) / bsz\n",
    "\n",
    "            update_train_log(train_log, loss_cls, loss_reg, hour_acc, minute_acc)\n",
    "\n",
    "            if i % 10 == 0:  # Print every 10 batches\n",
    "                print(f'Batch {i}/{len(trn_loader)} - Loss: {loss.item():.4f}, Hour Accuracy: {hour_acc:.4f}, Minute Accuracy: {minute_acc:.4f}')\n",
    "\n",
    "            if i == 0:\n",
    "                writer.add_images('train', img, ep)\n",
    "                if use_stn:\n",
    "                    writer.add_images('train_warped', img_, ep)\n",
    "        write_train_log(writer, train_log, use_stn, ep)\n",
    "\n",
    "        names = ['COCO', 'OpenImages'，'ClockMovies']\n",
    "        for i, vloader in enumerate([coco_loader, openimg_loader]):\n",
    "            eval_log = {'top_1': [], 'top_2': [], 'top_3': [], 'top_1_hr': [], 'top_1_min': [], 'iou50': []}\n",
    "            imgs = []\n",
    "            imgs_warped = []\n",
    "            for idx, val_sample in enumerate(vloader):\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    model_stn.eval()\n",
    "\n",
    "                    img, hour, minute, iou50 = val_sample\n",
    "                    img = img.float().to(device)\n",
    "                    hr = hour.type(torch.long).to(device)\n",
    "                    mn = minute.type(torch.long).to(device)\n",
    "\n",
    "                    # MODEL\n",
    "                    if use_stn:\n",
    "                        pred_st = model_stn(img)\n",
    "                        pred_st = torch.cat([pred_st, torch.ones(1, 1).to(device)], 1)\n",
    "                        Minv_pred = torch.reshape(pred_st, (-1, 3, 3))\n",
    "                        img_ = warp(img, Minv_pred)\n",
    "                        pred = model(img_)\n",
    "                    else:\n",
    "                        pred = model(img)\n",
    "\n",
    "                    # Top 3 predictions\n",
    "                    max_pred = torch.argsort(pred, dim=1, descending=True)\n",
    "                    max_pred = max_pred[0, :3]\n",
    "                    max_h = max_pred[0] // 60\n",
    "                    max_m = max_pred[0] % 60\n",
    "\n",
    "                    minute_err = torch.sum(torch.abs(max_m - mn))\n",
    "                    both_err = torch.abs(max_pred - (hr * 60 + mn))\n",
    "                    top_1 = float(both_err[0] <= 1) + float(both_err[0] == 719)\n",
    "                    top_2 = float(both_err[1] <= 1) + float(both_err[1] == 719)\n",
    "                    top_3 = float(both_err[2] <= 1) + float(both_err[2] == 719)\n",
    "                    top_1_hr = float(torch.sum(max_h == hr))\n",
    "                    top_1_min = float(minute_err <= 1) + float(minute_err == 59)\n",
    "\n",
    "                    update_eval_log(eval_log, top_1, top_2, top_3, top_1_hr, top_1_min, int(iou50))\n",
    "\n",
    "                    if idx < 64:\n",
    "                        imgs.append(img[0])\n",
    "                        if use_stn:\n",
    "                            imgs_warped.append(img_[0])\n",
    "\n",
    "            print(f'Evaluation on {names[i]} - Top 1 Accuracy: {sum(eval_log[\"top_1\"]) / len(eval_log[\"top_1\"]):.4f}')\n",
    "            writer.add_images(names[i], torch.stack(imgs, 0), ep)\n",
    "            if use_stn:\n",
    "                writer.add_images(names[i] + '_warped', torch.stack(imgs_warped, 0), ep)\n",
    "            write_eval_log(writer, eval_log, i, ep)\n",
    "\n",
    "        torch.save(model.state_dict(), '../models/{}.pth'.format(verbose))\n",
    "        if use_stn:\n",
    "            torch.save(model_stn.state_dict(), '../models/{}_st.pth'.format(verbose))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    # Ablations\n",
    "    parser.add_argument('--no_augment', action='store_true')\n",
    "    parser.add_argument('--no_homography', action='store_true')\n",
    "    parser.add_argument('--no_artefacts', action='store_true')\n",
    "    parser.add_argument('--no_stn', action='store_true')\n",
    "\n",
    "    parser.add_argument('--verbose', type=str, default='base')\n",
    "    parser.add_argument('--resume_path', type=str, default=None)\n",
    "    parser.add_argument('--stn_resume_path', type=str, default=None)\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be71b61",
   "metadata": {},
   "source": [
    "### label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ed735d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-animation-of-clock-arrows-walking-fast-clockwise-over-white-backgrount-time-passing-concept\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-animation-of-clock-arrows-walking-fast-clockwise-over-white-backgrount-time-passing-concept (1)\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-animation-of-clock-arrows-walking-fast-clockwise-over-white-backgrount-time-passing-concept (1)\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-animation-of-clock-arrows-walking-fast-clockwise-over-white-backgrount-time-passing-concept\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-day-to-night-time-lapse-at-the-fish-market-in-hamburg-germany\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-day-to-night-time-lapse-at-the-fish-market-in-hamburg-germany\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-timelapse-of-beautiful-classic-analog-clock-moving-fast-on-wall-background-alarm-clock-face-in\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage--k-timelapse-of-beautiful-classic-analog-clock-moving-fast-on-wall-background-alarm-clock-face-in\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-antique-alarm-clock-with-world-map-running-time-lapse-k\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-antique-alarm-clock-with-world-map-running-time-lapse-k\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-antique-clock-dial-close-up-vintage-pocket-watch\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-antique-clock-dial-close-up-vintage-pocket-watch\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-big-ben-clock-face-time-lapse-stunning-time-lapse-of-the-famous-big-ben-clock-tower-showing-the\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-big-ben-clock-face-time-lapse-stunning-time-lapse-of-the-famous-big-ben-clock-tower-showing-the\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-blue-alam-clock-o-clock-time-lapse-moving-fast-time-concept\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-blue-alam-clock-o-clock-time-lapse-moving-fast-time-concept\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-clock-counting-down-hour-day-fast-speed-clock-with-moving-arrows-clock-time-lapse-uhd-k\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-clock-counting-down-hour-day-fast-speed-clock-with-moving-arrows-clock-time-lapse-uhd-k\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-clock-face-close-up-in-time-lapse-on-black-background-clocks-running-fast-clock-dial-close-up\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-clock-face-close-up-in-time-lapse-on-black-background-clocks-running-fast-clock-dial-close-up\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-clock-face-in-time-lapse-on-white-wall-in-office\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-close-up-move-the-camera-angle-from-left-to-right-nine-o-clock-start-time-work-gray-wall-clock-on\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-closeup-of-white-clock-face-in-timelapse-in-daytime-of-office-dark-grey-wall (1)\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-edinburgh-uk-aerial-view-of-edinburgh-scotland-the-city-with-castle-and-clock-tower-during-the\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-fast-blur-of-clockwise-the-beginning-of-time-am-to-pm-run-fast-time-passing-hours-clock\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-green-clock-with-white-numbers-and-arrows-on-pink-background-time-lapse\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-grey-clock-with-white-numbers-and-hands-on-a-pink-background-time-interval-time-concept-d\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-london-uk-sunset-over-the-city-of-london-uk-colorful-sky-behind-westminster-and-big-ben\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-minimal-black-clock-isolated-showtime-nine-o-clock-on-white-background-time-lapse-minutes\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-modern-clock-face-fast-time-lapse-time-flies-moving-fast-forward-in-this-time-lapse-clock-face\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-old-weathered-down-vintage-clock-k-d-animation-of-a-weathered-down-vintage-clock-second\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-rush-hour-traffic-fast-moving-fast-moving-traffic-drives-time-lapse-clock-moving-fast-light-each (1)\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-rush-hour-traffic-fast-moving-fast-moving-traffic-drives-time-lapse-clock-moving-fast-light-each\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-simple-red-clock-the-dial-does-not-show-numbers-time-starts-walking-at-o-clock-on-white\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-the-time-on-the-clock-twelve-turquoise-clock-with-the-red-arrow-with-the-arabic-numerals-on-an\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-d-clock-animated-first-spinning-clocks-hand\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-footage-of-rush-hour-traffic-on-westminster-bridge-in-london-with-houses-of-parliament\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-of-a-clock-on-red-background\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-of-clock-hanging-on-red-wall\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-of-one-minute-on-quartz-clock-face-close-up-static-shot\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-on-a-modern-orange-wall-clock-wall-clock-show-the-running-time-close-up-to-a-wall\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-time-flies-time-runs-fast-on-the-wall-clock-video-symbolizing-fast-flies-of-time\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-time-lapse-video-am-pm-office-hours-businesspeople-does-routine-job-in-business-time-focus-on\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-timelapse-of-a-blue-clock-on-a-white-wall-the-clock-starts-ticking-at-and-ends-at\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-vintage-aged-pocket-watch-clock-timelapse-time-flowing-speed-analog-clock-motion\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-wall-clock-show-the-running-time-time-lapse-on-a-modern-wall-clock-at-noon-close-up-to-a-wall\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-wall-clock-show-the-running-time-time-lapse-on-a-modern-wall-clock-close-up-to-a-wall-clock\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-wall-clock-show-the-running-time-time-lapse-on-a-modern-white-wall-clock-close-up-to-a-wall\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-wall-clocks-different-time-lapse-hours-green-screen-background\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-white-alam-clock-o-clock-time-lapse-moving-fast-time-concept\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-white-office-clock-hanging-on-a-blue-color-wall\n",
      "关键帧已保存到文件夹: C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1\\stock-footage-zoom-out-twelve-o-clock-white-clock-face-beginning-of-time-am-time-lapse-minutes-moving\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "def create_folder_from_video(video_path):\n",
    "    # 获取视频文件名（不带扩展名）\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    \n",
    "    # 创建同名文件夹\n",
    "    folder_path = os.path.join(os.path.dirname(video_path), video_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    return folder_path\n",
    "\n",
    "def extract_keyframes(video_path, num_frames=10):\n",
    "    # 打开视频文件\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = max(frame_count // num_frames, 1)\n",
    "    \n",
    "    frames = []\n",
    "    for i in range(0, frame_count, frame_interval):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "        if len(frames) >= num_frames:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def save_frames_as_images(frames, folder_path):\n",
    "    for idx, frame in enumerate(frames):\n",
    "        # 将帧转换为PIL图像\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        img_path = os.path.join(folder_path, f\"{idx + 1}.png\")\n",
    "        img.save(img_path)\n",
    "\n",
    "def main(video_path):\n",
    "    # 创建同名文件夹\n",
    "    folder_path = create_folder_from_video(video_path)\n",
    "    \n",
    "    # 从视频中抽取关键帧\n",
    "    frames = extract_keyframes(video_path)\n",
    "    \n",
    "    # 保存关键帧为图片\n",
    "    save_frames_as_images(frames, folder_path)\n",
    "    \n",
    "    print(f\"关键帧已保存到文件夹: {folder_path}\")\n",
    "\n",
    "\n",
    "base_dir = 'C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1/'\n",
    "vids = natsorted([x for x in os.listdir(base_dir) if '-' in x])\n",
    "#     print([x for x in os.listdir(base_dir) if '-' in x])\n",
    "    \n",
    "for vid in vids:\n",
    "    extractKeyFrames(base_dir + vid)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddcf313",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 03:43:18,640 - INFO - Device set to cuda\n",
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "2024-05-16 03:43:19,541 - INFO - Loading model state from ../models/base.pth\n",
      "2024-05-16 03:43:19,727 - INFO - Loading STN model state from ../models/base_st.pth\n",
      "2024-05-16 03:43:19,973 - INFO - Found 78 videos for processing\n",
      "2024-05-16 03:43:19,973 - INFO - Processing video: stock-footage--k-animation-of-clock-arrows-walking-fast-clockwise-over-white-backgrount-time-passing-concept\n",
      "2024-05-16 03:43:19,974 - DEBUG - Selected 10 frames from video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "5\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 03:43:20,602 - DEBUG - RANSAC score: 0.6\n",
      "2024-05-16 03:43:20,602 - INFO - Video stock-footage--k-animation-of-clock-arrows-walking-fast-clockwise-over-white-backgrount-time-passing-concept is not valid\n",
      "2024-05-16 03:43:20,603 - INFO - Processing video: stock-footage--k-animation-of-clock-arrows-walking-fast-clockwise-over-white-backgrount-time-passing-concept.mp4\n",
      "2024-05-16 03:43:20,604 - DEBUG - Selected 10 frames from video\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "5\n",
      "True\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 168\u001b[0m\n\u001b[0;32m    166\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--no_save\u001b[39m\u001b[38;5;124m'\u001b[39m, action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_true\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    167\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args(args\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m--> 168\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 95\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m imgs:\n\u001b[0;32m     94\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(base_dir \u001b[38;5;241m+\u001b[39m vid \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m i)\n\u001b[1;32m---> 95\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\n\u001b[0;32m     97\u001b[0m     img \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh w c -> c h w\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import einops\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import ArgumentParser\n",
    "from utils import warp\n",
    "from natsort import natsorted\n",
    "from cyclic_ransac import RANSACRegressor\n",
    "import logging\n",
    "\n",
    "def main(args):\n",
    "    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger()\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    logger.info(f'Device set to {device}')\n",
    "\n",
    "    # MODEL\n",
    "    model_stn = models.resnet50(pretrained=True)\n",
    "    model_stn.fc = nn.Linear(2048, 8)\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(2048, 720)\n",
    "    \n",
    "    base_dir = 'C:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/1/'\n",
    "    resume_path = f'../models/{args.verbose}.pth'\n",
    "    stn_resume_path = f'../models/{args.verbose}_st.pth'\n",
    "    \n",
    "    logger.info(f'Loading model state from {resume_path}')\n",
    "    model.load_state_dict(torch.load(resume_path))\n",
    "    logger.info(f'Loading STN model state from {stn_resume_path}')\n",
    "    model_stn.load_state_dict(torch.load(stn_resume_path))\n",
    "    \n",
    "    model.eval()\n",
    "    model_stn.eval()\n",
    "    \n",
    "    model.to(device)\n",
    "    model_stn.to(device)\n",
    "    \n",
    "    min_vid_length = 5\n",
    "    min_range = 20\n",
    "    score_threshold = 0.7\n",
    "    ransac_threshold = 3\n",
    "\n",
    "    os.makedirs('../data/labels', exist_ok=True)\n",
    "    os.makedirs('../plots/pos', exist_ok=True)\n",
    "    os.makedirs('../plots/neg', exist_ok=True)\n",
    "    \n",
    "#     if not args.no_save:\n",
    "#         label_path = f'../data/labels/{args.verbose}.txt'\n",
    "#         if os.path.isfile(label_path):\n",
    "#             logger.info(f'Removing existing label file {label_path}')\n",
    "#             os.remove(label_path)\n",
    "    \n",
    "    label_path = f'../data/labels/{args.verbose}.txt'\n",
    "#     if os.path.isfile(label_path):\n",
    "#         logger.info(f'Removing existing label file {label_path}')\n",
    "#         os.remove(label_path)\n",
    "    \n",
    "    vids = natsorted([x for x in os.listdir(base_dir) if '-' in x])\n",
    "#     print([x for x in os.listdir(base_dir) if '-' in x])\n",
    "    logger.info(f'Found {len(vids)} videos for processing')\n",
    "    \n",
    "    \n",
    "#     for vid in vids:\n",
    "#         extractKeyFrames(base_dir + vid)\n",
    "    \n",
    "    \n",
    "    for vid in vids:\n",
    "#         print(vid)\n",
    "        logger.info(f'Processing video: {vid}')\n",
    "        base_name = os.path.splitext(vid)[0]\n",
    "        imgs = natsorted([x for x in os.listdir(base_dir + base_name) if '.png' in x])\n",
    "        ids = [int(x.strip('.png')) for x in imgs]\n",
    "        \n",
    "        print(len(imgs))\n",
    "        print(min_vid_length)\n",
    "        print(len(imgs) > min_vid_length)\n",
    "        \n",
    "        \n",
    "        if len(imgs) > min_vid_length:\n",
    "            length = len(imgs)\n",
    "            frame_gap = len(imgs) // 100 + 1\n",
    "            imgs = imgs[::frame_gap]\n",
    "            logger.debug(f'Selected {len(imgs)} frames from video')\n",
    "            \n",
    "            data = []\n",
    "            for i in imgs:\n",
    "                img = cv2.imread(base_dir + vid + '/' + i)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "                img = einops.rearrange(img, 'h w c -> c h w') / 255.\n",
    "                data.append(img)\n",
    "            data = np.stack(data, 0)\n",
    "            \n",
    "            data = torch.Tensor(data).float().to(device)\n",
    "            \n",
    "            pred_st = model_stn(data)\n",
    "            pred_st = torch.cat([pred_st, torch.ones(len(imgs), 1).to(device)], 1)\n",
    "            Minv_pred = torch.reshape(pred_st, (-1, 3, 3))\n",
    "            data_ = warp(data, Minv_pred, sz=224)\n",
    "            \n",
    "            pred = model(data_)\n",
    "            max_pred = torch.argsort(pred, dim=1, descending=True)\n",
    "            max_pred = max_pred[:, 0].detach().cpu().numpy()\n",
    "            \n",
    "            X = np.array([int(x.strip('.png')) for x in imgs]).reshape(-1, 1)\n",
    "            y = max_pred\n",
    "            ransac = RANSACRegressor(residual_threshold=ransac_threshold, stop_probability=0.999)\n",
    "            ransac.fit(X, y)\n",
    "            inlier_mask = ransac.inlier_mask_\n",
    "            outlier_mask = np.logical_not(inlier_mask)\n",
    "            line_X = np.array(ids).reshape(-1, 1)\n",
    "            line_y_ransac = ransac.predict(line_X)\n",
    "            line_y_plot = ransac.predict(X)\n",
    "            score = np.sum(inlier_mask) / len(imgs)\n",
    "            logger.debug(f'RANSAC score: {score}')\n",
    "            \n",
    "            if (score > score_threshold) and (np.max(line_y_ransac) - np.min(line_y_ransac) > min_range):\n",
    "                valid = True\n",
    "                logger.info(f'Video {vid} is valid')\n",
    "            else:\n",
    "                valid = False\n",
    "                logger.info(f'Video {vid} is not valid')\n",
    "            \n",
    "            if args.plot:\n",
    "                plt.plot()\n",
    "                plt.scatter(X[inlier_mask], y[inlier_mask], color=\"yellowgreen\", marker=\".\", label=\"Inliers\")\n",
    "                plt.scatter(X[outlier_mask], y[outlier_mask], color=\"gold\", marker=\".\", label=\"Outliers\")\n",
    "                plt.plot(line_X, line_y_ransac, color=\"cornflowerblue\", linewidth=2, label=\"RANSAC regressor\")\n",
    "                folder = 'pos' if valid else 'neg'\n",
    "                plt.savefig(f'../plots/{folder}/{vid}.png')\n",
    "                plt.close()\n",
    "                img_ = cv2.imread(f'../plots/{folder}/{vid}.png')\n",
    "                H, W, _ = np.shape(img_)\n",
    "                if valid:\n",
    "                    cv2.rectangle(img_, (0, 0), (W, H), (0, 255, 0), 20)\n",
    "                else:\n",
    "                    cv2.rectangle(img_, (0, 0), (W, H), (0, 0, 255), 20)\n",
    "                x = int(len(imgs) // 7)\n",
    "                for i in [0, x, 2*x, 3*x, 4*x, 5*x, 6*x, len(imgs)-1]:\n",
    "                    img_i = cv2.imread(base_dir + vid + '/' + imgs[i])\n",
    "                    img_i = cv2.resize(img_i, (W, H))\n",
    "                    if abs(line_y_plot[i] - y[i]) % 720 <= 3:\n",
    "                        cv2.rectangle(img_i, (0, 0), (W, H), (0, 255, 0), 20)\n",
    "                    else:\n",
    "                        cv2.rectangle(img_i, (0, 0), (W, H), (0, 0, 255), 20)\n",
    "                    img_ = np.concatenate([img_, np.ones([H, 40, 3])*255, img_i], 1)\n",
    "                cv2.imwrite(f'../plots/{folder}/{vid}.png', img_)\n",
    "            \n",
    "            if valid and not args.no_save:\n",
    "                print('hello')\n",
    "                with open(label_path, 'a') as f:\n",
    "                    f.write(vid + ',' + str(list(np.rint(line_y_ransac).astype(int))))\n",
    "                    f.write('\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--verbose', type=str, default='base')\n",
    "    parser.add_argument('--plot', action='store_true')\n",
    "    parser.add_argument('--no_save', action='store_true')\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69553fe1",
   "metadata": {},
   "source": [
    "### refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7481e8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/labels/base.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 170\u001b[0m\n\u001b[0;32m    167\u001b[0m parser\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--verbose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    169\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args(args\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m--> 170\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 29\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# DATASET\u001b[39;00m\n\u001b[0;32m     28\u001b[0m trn_dataset \u001b[38;5;241m=\u001b[39m ClockSyn(augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_homography\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_artefacts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 29\u001b[0m timelapse_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mClockTimelapse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/labels/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m coco_dataset \u001b[38;5;241m=\u001b[39m ClockEval(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m openimg_dataset \u001b[38;5;241m=\u001b[39m ClockEval(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenimages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\itsabouttime-main\\itsabouttime-main\\src\\data.py:171\u001b[0m, in \u001b[0;36mClockTimelapse.__init__\u001b[1;34m(self, anno_dir, augment)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Administrator/Desktop/itsabouttime-main/itsabouttime-main/data/filtered_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manno_dir \u001b[38;5;241m=\u001b[39m anno_dir\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manno_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    172\u001b[0m   anno \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/labels/base.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import einops\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from argparse import ArgumentParser\n",
    "from torch.utils.data import DataLoader\n",
    "from data import *\n",
    "from utils import warp, update_train_log, write_train_log, update_eval_log, write_eval_log\n",
    "\n",
    "def main(args):\n",
    "  bsz = 32\n",
    "  lr = 1e-4\n",
    "  verbose = args.verbose\n",
    "  use_stn = not args.no_stn\n",
    "\n",
    "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "  dt_string = datetime.now().strftime(\"%m_%d_%H_%M\")\n",
    "  writer = SummaryWriter(logdir='../logs/{}-{}'.format(dt_string, verbose))\n",
    "\n",
    "  # DATASET\n",
    "  trn_dataset = ClockSyn(augment=True, use_homography=True, use_artefacts=True)\n",
    "  timelapse_dataset = ClockTimelapse('../data/labels/{}.txt'.format(args.verbose), augment=True)\n",
    "  coco_dataset = ClockEval('coco')\n",
    "  openimg_dataset = ClockEval('openimages')\n",
    "  movie_dataset = ClockEval('clockmovies')\n",
    "  trn_loader = DataLoader(trn_dataset, batch_size=bsz, shuffle=True)\n",
    "  timelapse_loader = DataLoader(timelapse_dataset, batch_size=bsz, shuffle=True, drop_last=True)\n",
    "  coco_loader = DataLoader(coco_dataset, batch_size=1, shuffle=False)\n",
    "  openimg_loader = DataLoader(openimg_dataset, batch_size=1, shuffle=False)\n",
    "  movie_loader = DataLoader(movie_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "  # MODEL\n",
    "  model_stn = models.resnet50(pretrained=True)\n",
    "  model_stn.fc = nn.Linear(2048, 8)\n",
    "  model = models.resnet50(pretrained=True)\n",
    "  model.fc = nn.Linear(2048, 720)\n",
    "  resume_path = '../models/{}.pth'.format(args.verbose)\n",
    "  stn_resume_path = '../models/{}_st.pth'.format(args.verbose)\n",
    "  model.load_state_dict(torch.load(resume_path))\n",
    "  model_stn.load_state_dict(torch.load(stn_resume_path))\n",
    "  model_stn.to(device)\n",
    "  model.to(device)\n",
    "\n",
    "  #OPTIM\n",
    "  optimizer = optim.Adam(list(model.parameters()) + list(model_stn.parameters()), lr=lr)\n",
    "  cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  for ep in range(0):\n",
    "    print('Epoch {}'.format(ep))\n",
    "    train_log = {'loss_cls': [], 'loss_reg': [], 'hour_acc': [], 'minute_acc': []}\n",
    "\n",
    "    for i, trn_sample in enumerate(zip(trn_loader, timelapse_loader)):\n",
    "      model.train()\n",
    "      model_stn.train()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      img, hour, minute, Minv = trn_sample[0]\n",
    "      img2, hour2, minute2 = trn_sample[1]\n",
    "\n",
    "      img = torch.cat([img, img2], 0)\n",
    "      hour = torch.cat([hour, hour2], 0)\n",
    "      minute = torch.cat([minute, minute2], 0)\n",
    "\n",
    "      img = img.float().to(device)\n",
    "      Minv = Minv.to(device)\n",
    "      hour = hour.type(torch.long).to(device)\n",
    "      minute = minute.type(torch.long).to(device)\n",
    "\n",
    "      # PREDICT\n",
    "      if use_stn:\n",
    "        pred_st = model_stn(img)\n",
    "        pred_st = torch.cat([pred_st,torch.ones(bsz*2,1).to(device)], 1)\n",
    "        Minv_pred = torch.reshape(pred_st, (-1, 3, 3))\n",
    "        img_ = warp(img, Minv_pred)\n",
    "        if random.random() < 0.5:\n",
    "          pred = model(img_)\n",
    "        else:\n",
    "          pred = model(img)\n",
    "        loss_reg = torch.mean(torch.abs((Minv.reshape(bsz,9) - pred_st[:bsz])))\n",
    "        loss_cls = cross_entropy(pred, hour * 60 + minute)\n",
    "      else:\n",
    "        pred = model(img)\n",
    "        loss_cls = cross_entropy(pred, hour * 60 + minute)\n",
    "        loss_reg = 0.\n",
    "\n",
    "      # LOSS\n",
    "      loss = 100 * loss_reg + loss_cls\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # METRIC\n",
    "      max_pred = torch.argsort(pred, dim=1, descending=True)  \n",
    "      max_pred = max_pred[:,0]\n",
    "      max_h = max_pred // 60\n",
    "      max_m = max_pred % 60\n",
    "      hour_acc = float(torch.sum(max_h == hour)) / (2*bsz)\n",
    "      minute_acc = float(torch.sum(torch.abs(max_m - minute) <= 1)) / (2*bsz)\n",
    "\n",
    "      update_train_log(train_log, loss_cls, loss_reg, hour_acc, minute_acc)\n",
    "      if i == 0:\n",
    "        writer.add_images('train', img, ep)\n",
    "        if use_stn: writer.add_images('train_warped', img_, ep)\n",
    "    write_train_log(writer, train_log, use_stn, ep)\n",
    "\n",
    "    names = ['COCO', 'OpenImages','ClockMovies']\n",
    "    for i, vloader in enumerate([coco_loader, openimg_loader, movie_loader]):\n",
    "      eval_log = {'top_1': [],'top_2': [],'top_3': [],'top_1_hr': [], 'top_1_min': [], 'iou50': []}\n",
    "      imgs = []\n",
    "      imgs_warped = []\n",
    "      for idx, val_sample in enumerate(vloader):\n",
    "        with torch.no_grad():\n",
    "          model.eval()\n",
    "          model_stn.eval()\n",
    "          \n",
    "          img, hour, minute, iou50 = val_sample\n",
    "          img = img.float().to(device)\n",
    "          hr = hour.type(torch.long).to(device)\n",
    "          mn = minute.type(torch.long).to(device)\n",
    "\n",
    "          #MODEL\n",
    "          if use_stn:\n",
    "            pred_st = model_stn(img)\n",
    "            pred_st = torch.cat([pred_st,torch.ones(1,1).to(device)], 1)\n",
    "            Minv_pred = torch.reshape(pred_st, (-1, 3, 3))\n",
    "            img_ = warp(img, Minv_pred)\n",
    "            pred = model(img_)\n",
    "          else:\n",
    "            pred = model(img)  \n",
    "\n",
    "          #top 3 predictions\n",
    "          max_pred = torch.argsort(pred, dim=1, descending=True)\n",
    "          max_pred = max_pred[0,:3]\n",
    "          max_h = max_pred[0] // 60\n",
    "          max_m = max_pred[0] % 60\n",
    "\n",
    "          minute_err = torch.sum(torch.abs(max_m - mn))\n",
    "          both_err = torch.abs(max_pred - (hr * 60 + mn))\n",
    "          top_1 = float(both_err[0] <= 1) + float(both_err[0] == 719)\n",
    "          top_2 = float(both_err[1] <= 1) + float(both_err[1] == 719)\n",
    "          top_3 = float(both_err[2] <= 1) + float(both_err[2] == 719)\n",
    "          top_1_hr = float(torch.sum(max_h == hr))\n",
    "          top_1_min = float(minute_err <= 1) + float(minute_err == 59)\n",
    "\n",
    "          update_eval_log(eval_log, top_1, top_2, top_3, top_1_hr, top_1_min, int(iou50))\n",
    "\n",
    "          if idx < 64:\n",
    "            imgs.append(img[0])\n",
    "            if use_stn: imgs_warped.append(img_[0])        \n",
    "      writer.add_images(names[i], torch.stack(imgs,0), ep)\n",
    "      if use_stn: writer.add_images(names[i]+'_warped', torch.stack(imgs_warped,0), ep)\n",
    "      write_eval_log(writer, eval_log, i, ep)\n",
    "\n",
    "    torch.save(model.state_dict(), '../models/{}+.pth'.format(verbose))\n",
    "    if use_stn: torch.save(model_stn.state_dict(), '../models/{}+_st.pth'.format(verbose))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--no_stn', action='store_true')\n",
    "    parser.add_argument('--verbose', type=str, default='base')\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257545d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
